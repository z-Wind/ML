{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"HW03_CNN_ResNet18.ipynb","provenance":[],"collapsed_sections":["Zkw8lNSe1oPo"]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# HW3 Image Classification\n","## We strongly recommend that you run with Kaggle for this homework\n","https://www.kaggle.com/c/ml2022spring-hw3b/code?competitionId=34954&sortBy=dateCreated"],"metadata":{"id":"i7KWwvLl1oOr"}},{"cell_type":"code","source":["_exp_name = \"resnet18\"\n","!nvidia-smi"],"metadata":{"papermill":{"duration":0.0189,"end_time":"2022-02-23T10:03:06.279758","exception":false,"start_time":"2022-02-23T10:03:06.260858","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:17:20.268569Z","iopub.execute_input":"2022-07-13T12:17:20.268923Z","iopub.status.idle":"2022-07-13T12:17:21.033630Z","shell.execute_reply.started":"2022-07-13T12:17:20.268878Z","shell.execute_reply":"2022-07-13T12:17:21.032781Z"},"trusted":true,"id":"JqwW1dP-1oO4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torchinfo"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:21.035245Z","iopub.execute_input":"2022-07-13T12:17:21.035564Z","iopub.status.idle":"2022-07-13T12:17:30.381975Z","shell.execute_reply.started":"2022-07-13T12:17:21.035529Z","shell.execute_reply":"2022-07-13T12:17:30.380891Z"},"trusted":true,"id":"KNxm8Am41oO9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get Data\n","Notes: if the links are dead, you can download the data directly from Kaggle and upload it to the workspace, or you can use the Kaggle API to directly download the data into colab.\n"],"metadata":{"id":"SA6UBQdt1oO-"}},{"cell_type":"code","source":["# #! wget https://www.dropbox.com/s/6l2vcvxl54b0b6w/food11.zip\n","# ! wget -O food11.zip \"https://github.com/virginiakm1988/ML2022-Spring/blob/main/HW03/food11.zip?raw=true\"\n","# ! unzip food11.zip"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:30.383958Z","iopub.execute_input":"2022-07-13T12:17:30.384251Z","iopub.status.idle":"2022-07-13T12:17:30.389379Z","shell.execute_reply.started":"2022-07-13T12:17:30.384219Z","shell.execute_reply":"2022-07-13T12:17:30.388449Z"},"trusted":true,"id":"L1ZMAeOx1oO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import necessary packages.\n","import pandas as pd\n","import numpy as np\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from PIL import Image\n","# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n","from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset, random_split\n","from torchvision.datasets import DatasetFolder, VisionDataset\n","from torchinfo import summary\n","\n","# This is for the progress bar.\n","from tqdm.auto import tqdm\n","import random"],"metadata":{"papermill":{"duration":1.654263,"end_time":"2022-02-23T10:03:07.947242","exception":false,"start_time":"2022-02-23T10:03:06.292979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:17:30.392366Z","iopub.execute_input":"2022-07-13T12:17:30.392630Z","iopub.status.idle":"2022-07-13T12:17:30.404340Z","shell.execute_reply.started":"2022-07-13T12:17:30.392598Z","shell.execute_reply":"2022-07-13T12:17:30.403250Z"},"trusted":true,"id":"HZY_2Sw_1oPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cuda = True if torch.cuda.is_available() else False\n","device = torch.device('cuda:0' if cuda else 'cpu')\n","FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","device"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:30.405573Z","iopub.execute_input":"2022-07-13T12:17:30.405857Z","iopub.status.idle":"2022-07-13T12:17:30.423629Z","shell.execute_reply.started":"2022-07-13T12:17:30.405818Z","shell.execute_reply":"2022-07-13T12:17:30.422786Z"},"trusted":true,"id":"yYrmj5bA1oPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["myseed = 3  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"],"metadata":{"papermill":{"duration":0.078771,"end_time":"2022-02-23T10:03:08.039428","exception":false,"start_time":"2022-02-23T10:03:07.960657","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:17:30.425114Z","iopub.execute_input":"2022-07-13T12:17:30.425401Z","iopub.status.idle":"2022-07-13T12:17:30.439484Z","shell.execute_reply.started":"2022-07-13T12:17:30.425341Z","shell.execute_reply":"2022-07-13T12:17:30.438382Z"},"trusted":true,"id":"UMZe5BMD1oPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def no_axis_show(img, title='', cmap=None):\n","    # imshow, and set the interpolation mode to be \"nearest\"。\n","    fig = plt.imshow(img, interpolation='nearest', cmap=cmap)\n","    # do not show the axes in the images.\n","    fig.axes.get_xaxis().set_visible(False)\n","    fig.axes.get_yaxis().set_visible(False)\n","    plt.title(title)"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:30.440515Z","iopub.execute_input":"2022-07-13T12:17:30.440745Z","iopub.status.idle":"2022-07-13T12:17:30.455609Z","shell.execute_reply.started":"2022-07-13T12:17:30.440709Z","shell.execute_reply":"2022-07-13T12:17:30.454581Z"},"trusted":true,"id":"aBsajzQk1oPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["titles = [\"Bread\", \"Dairy product\", \"Dessert\", \"Egg\", \"Fried food\", \"Meat\", \"Noodles/Pasta\", \"Rice\", \"Seafood\", \"Soup\", \"Vegetable/Fruit\"]\n","for i in range(11):\n","    plt.figure(figsize=(18, 18))\n","    for j in range(10):\n","        plt.subplot(1, 10, j+1)\n","        fig = no_axis_show(plt.imread(f'../input/ml2022spring-hw3b/food11/training/{i}_{j}.jpg'), title=titles[i])\n","    plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:30.457181Z","iopub.execute_input":"2022-07-13T12:17:30.457420Z","iopub.status.idle":"2022-07-13T12:17:39.827314Z","shell.execute_reply.started":"2022-07-13T12:17:30.457391Z","shell.execute_reply":"2022-07-13T12:17:39.825991Z"},"trusted":true,"id":"bn0rFLGP1oPL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hyperparameter"],"metadata":{"id":"GTXISUrB1oPN"}},{"cell_type":"code","source":["# The number of training epochs and patience.\n","n_epochs = 200\n","patience = 50 # If no improvement in 'patience' epochs, early stop\n","\n","_dataset_dir = \"../input/ml2022spring-hw3b/food11\"\n","\n","batch_size = 32\n","valid_ratio = 0.1\n","lr = 0.001\n","weight_decay = 2e-5"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:39.829163Z","iopub.execute_input":"2022-07-13T12:17:39.829876Z","iopub.status.idle":"2022-07-13T12:17:39.835519Z","shell.execute_reply.started":"2022-07-13T12:17:39.829820Z","shell.execute_reply":"2022-07-13T12:17:39.834850Z"},"trusted":true,"id":"X07vlvTZ1oPO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Transforms**\n","Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n","\n","Please refer to PyTorch official website for details about different transforms."],"metadata":{"papermill":{"duration":0.01289,"end_time":"2022-02-23T10:03:08.065357","exception":false,"start_time":"2022-02-23T10:03:08.052467","status":"completed"},"tags":[],"id":"ZDanCzuu1oPH"}},{"cell_type":"code","source":["MEAN = torch.tensor([0.485, 0.456, 0.406]).to(device)\n","STD = torch.tensor([0.229, 0.224, 0.225]).to(device)\n","\n","# Normally, We don't need augmentations in testing and validation.\n","# All we need here is to resize the PIL image and transform it into Tensor.\n","test_tfm = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=MEAN, std=STD),\n","])\n","\n","# However, it is also possible to use augmentation in the testing phase.\n","# You may use train_tfm to produce a variety of images and then test using ensemble methods\n","train_tfm = transforms.Compose([\n","    # add some useful transform or augmentation here, according to your experience in HW3.\n","    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),#随机裁剪到 256*256\n","#     transforms.Resize(256),  # You can change this\n","    transforms.CenterCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=MEAN, std=STD),\n","])"],"metadata":{"papermill":{"duration":0.021406,"end_time":"2022-02-23T10:03:08.099437","exception":false,"start_time":"2022-02-23T10:03:08.078031","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:17:39.836577Z","iopub.execute_input":"2022-07-13T12:17:39.836834Z","iopub.status.idle":"2022-07-13T12:17:39.865457Z","shell.execute_reply.started":"2022-07-13T12:17:39.836775Z","shell.execute_reply":"2022-07-13T12:17:39.864623Z"},"trusted":true,"id":"_NrfKDZa1oPR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Datasets**\n","The data is labelled by the name, so we load images and label while calling '__getitem__'"],"metadata":{"papermill":{"duration":0.012739,"end_time":"2022-02-23T10:03:08.125181","exception":false,"start_time":"2022-02-23T10:03:08.112442","status":"completed"},"tags":[],"id":"sAN26Wxx1oPP"}},{"cell_type":"code","source":["class FoodDataset(Dataset):\n","\n","    def __init__(self,paths, tfm, files = None):\n","        super(FoodDataset).__init__()\n","        self.paths = paths\n","        self.files = sorted([os.path.join(path,x) for path in paths for x in os.listdir(path) if x.endswith(\".jpg\")])\n","        if files != None:\n","            self.files = files\n","        print(f\"One {paths} sample\",self.files[0])\n","        self.transform = tfm\n","  \n","    def __len__(self):\n","        return len(self.files)\n","  \n","    def __getitem__(self,idx):\n","        fname = self.files[idx]\n","        im = Image.open(fname)\n","        im = self.transform(im)\n","        \n","        try:\n","            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n","        except:\n","            label = -1 # test has no label\n","        return im, label"],"metadata":{"papermill":{"duration":0.023022,"end_time":"2022-02-23T10:03:08.160912","exception":false,"start_time":"2022-02-23T10:03:08.13789","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:17:39.867071Z","iopub.execute_input":"2022-07-13T12:17:39.867435Z","iopub.status.idle":"2022-07-13T12:17:39.883239Z","shell.execute_reply.started":"2022-07-13T12:17:39.867390Z","shell.execute_reply":"2022-07-13T12:17:39.881840Z"},"trusted":true,"id":"ubV_-hbC1oPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_valid_split(data_set, valid_ratio, seed):\n","    '''Split provided training data into training set and validation set'''\n","    valid_set_size = int(valid_ratio * len(data_set)) \n","    train_set_size = len(data_set) - valid_set_size\n","    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n","    return train_set, valid_set"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:39.885910Z","iopub.execute_input":"2022-07-13T12:17:39.886216Z","iopub.status.idle":"2022-07-13T12:17:39.898747Z","shell.execute_reply.started":"2022-07-13T12:17:39.886182Z","shell.execute_reply":"2022-07-13T12:17:39.897980Z"},"trusted":true,"id":"08taKBLu1oPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_set1 = FoodDataset([os.path.join(_dataset_dir,\"training\")], tfm=train_tfm)\n","data_set2 = FoodDataset([os.path.join(_dataset_dir,\"validation\")], tfm=train_tfm)\n","\n","data_set = ConcatDataset([data_set1, data_set2])\n","train_set, valid_set = train_valid_split(data_set, valid_ratio, myseed)\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","\n","print(\"train:\", len(train_set))\n","print(\"valid:\", len(valid_set))"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:39.900476Z","iopub.execute_input":"2022-07-13T12:17:39.900822Z","iopub.status.idle":"2022-07-13T12:17:40.351103Z","shell.execute_reply.started":"2022-07-13T12:17:39.900756Z","shell.execute_reply":"2022-07-13T12:17:40.350329Z"},"trusted":true,"id":"wN5OUg-j1oPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tensor_show(imgs, size_inches=(15, 10)):\n","    if not isinstance(imgs, list):\n","        imgs = [imgs]\n","    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n","    fig.set_size_inches(*size_inches)\n","    for i, img in enumerate(imgs):\n","        img = torchvision.transforms.functional.to_pil_image(img)\n","        axs[0, i].imshow(np.asarray(img))\n","        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n","    plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:40.352314Z","iopub.execute_input":"2022-07-13T12:17:40.353086Z","iopub.status.idle":"2022-07-13T12:17:40.365074Z","shell.execute_reply.started":"2022-07-13T12:17:40.353037Z","shell.execute_reply":"2022-07-13T12:17:40.363890Z"},"trusted":true,"id":"KQ8Bg_QY1oPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchvision\n","\n","recover_from_normalize = lambda img: img * STD[:, None, None] + MEAN[:, None, None]\n","\n","imgs = iter(train_loader).next()[0][:30]\n","grid = torchvision.utils.make_grid([recover_from_normalize(img.to(device)) for img in imgs], nrow=10)\n","tensor_show(grid, size_inches=(15, 5))\n","\n","imgs = iter(valid_loader).next()[0][:30]\n","grid = torchvision.utils.make_grid([recover_from_normalize(img.to(device)) for img in imgs], nrow=10)\n","tensor_show(grid, size_inches=(15, 5))"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:40.366925Z","iopub.execute_input":"2022-07-13T12:17:40.368239Z","iopub.status.idle":"2022-07-13T12:17:42.575704Z","shell.execute_reply.started":"2022-07-13T12:17:40.368120Z","shell.execute_reply":"2022-07-13T12:17:42.574581Z"},"trusted":true,"id":"QoNumgED1oPY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"MHSUHkJ11oPZ"}},{"cell_type":"code","source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n","        # input 維度 [3, 128, 128]\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n","\n","            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n","\n","            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n","\n","            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n","            \n","            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(512*4*4, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 11)\n","        )\n","\n","    def forward(self, x):\n","        out = self.cnn(x)\n","        out = out.view(out.size()[0], -1)\n","        return self.fc(out)"],"metadata":{"papermill":{"duration":0.0258,"end_time":"2022-02-23T10:03:08.199437","exception":false,"start_time":"2022-02-23T10:03:08.173637","status":"completed"},"tags":[],"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-07-13T12:17:42.577791Z","iopub.execute_input":"2022-07-13T12:17:42.578458Z","iopub.status.idle":"2022-07-13T12:17:42.601670Z","shell.execute_reply.started":"2022-07-13T12:17:42.578403Z","shell.execute_reply":"2022-07-13T12:17:42.599646Z"},"trusted":true,"id":"m-KqHCoQ1oPa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 自實現 ResNet18"],"metadata":{"id":"TDafdvF41oPb"}},{"cell_type":"code","source":["# https://zhuanlan.zhihu.com/p/157134695\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, inchannel, outchannel, stride=1):\n","        super(ResBlock, self).__init__()\n","        #这里定义了残差块内连续的2个卷积层\n","        self.left = nn.Sequential(\n","            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(outchannel)\n","        )\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or inchannel != outchannel:\n","            #shortcut，这里为了跟2个卷积层的结果结构一致，要做处理\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(outchannel)\n","            )\n","            \n","    def forward(self, x):\n","        out = self.left(x)\n","        #将2个卷积层的输出跟处理过的x相加，实现ResNet的基本结构\n","        out = out + self.shortcut(x)\n","        out = nn.functional.relu(out)\n","        \n","        return out"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:42.604185Z","iopub.execute_input":"2022-07-13T12:17:42.605363Z","iopub.status.idle":"2022-07-13T12:17:42.621392Z","shell.execute_reply.started":"2022-07-13T12:17:42.605306Z","shell.execute_reply":"2022-07-13T12:17:42.619959Z"},"trusted":true,"id":"-PUsabqH1oPc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ResNet18(nn.Module):\n","    def __init__(self, ResBlock, num_classes=11):\n","        super(ResNet18, self).__init__()\n","        self.inchannel = 64\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU()\n","        )\n","        self.layer1 = self.make_layer(ResBlock, 64, 2, stride=1)\n","        self.layer2 = self.make_layer(ResBlock, 128, 2, stride=2)\n","        self.layer3 = self.make_layer(ResBlock, 256, 2, stride=2)        \n","        self.layer4 = self.make_layer(ResBlock, 512, 2, stride=2)        \n","        self.fc = nn.Linear(8192, num_classes)\n","#         self.dropout = nn.Dropout(p=0.25)  # dropout\n","    #这个函数主要是用来，重复同一个残差块    \n","    def make_layer(self, block, channels, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.inchannel, channels, stride))\n","            self.inchannel = channels\n","        return nn.Sequential(*layers)\n","    \n","    def forward(self, x):\n","        #在这里，整个ResNet18的结构就很清晰了\n","        out = self.conv1(x) # [64, 128, 128]\n","        out = self.layer1(out) # [64, 128, 128]\n","        out = self.layer2(out) # [128, 64, 64]\n","        out = self.layer3(out) # [256, 32, 32]\n","        out = self.layer4(out) # [512, 16, 16]\n","        out = nn.functional.avg_pool2d(out, 4) # [512, 4, 4]\n","#         out = self.dropout(out) # dropout\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:42.623403Z","iopub.execute_input":"2022-07-13T12:17:42.624011Z","iopub.status.idle":"2022-07-13T12:17:42.646160Z","shell.execute_reply.started":"2022-07-13T12:17:42.623961Z","shell.execute_reply":"2022-07-13T12:17:42.644684Z"},"trusted":true,"id":"Veks3tQ61oPd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EasyNet(nn.Module):\n","    def __init__(self):\n","        super(EasyNet, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(3),\n","            nn.ReLU()\n","        )     \n","        self.fc = nn.Linear(3*32*32, 11)\n","    \n","    def forward(self, x):\n","        out = self.conv1(x) # [3, 128, 128]\n","        out = nn.functional.avg_pool2d(out, 4) # [3, 32, 32]\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:42.651701Z","iopub.execute_input":"2022-07-13T12:17:42.652333Z","iopub.status.idle":"2022-07-13T12:17:42.666599Z","shell.execute_reply.started":"2022-07-13T12:17:42.652282Z","shell.execute_reply":"2022-07-13T12:17:42.665142Z"},"trusted":true,"id":"J0v2mJSc1oPe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Warmup"],"metadata":{"id":"IDtKEPno1oPf"}},{"cell_type":"code","source":["def get_cosine_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps: int,\n","    num_training_steps: int,\n","    num_cycles: float = 0.5,\n","    last_epoch: int = -1,\n","):\n","    \"\"\"\n","    Create a schedule with a learning rate that decreases following the values of the cosine function between the\n","    initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n","    initial lr set in the optimizer.\n","\n","    Args:\n","        optimizer (:class:`~torch.optim.Optimizer`):\n","        The optimizer for which to schedule the learning rate.\n","        num_warmup_steps (:obj:`int`):\n","        The number of steps for the warmup phase.\n","        num_training_steps (:obj:`int`):\n","        The total number of training steps.\n","        num_cycles (:obj:`float`, `optional`, defaults to 0.5):\n","        The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n","        following a half-cosine).\n","        last_epoch (:obj:`int`, `optional`, defaults to -1):\n","        The index of the last epoch when resuming training.\n","\n","    Return:\n","        :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n","    \"\"\"\n","    def lr_lambda(current_step, lowerbound=0.003):\n","        # Warmup\n","        if current_step < num_warmup_steps:\n","            return max(lowerbound, float(current_step) / float(max(1, num_warmup_steps)))\n","        # decadence\n","        progress = float(current_step - num_warmup_steps) / float(\n","            max(1, num_training_steps - num_warmup_steps)\n","        )\n","        return max(\n","            lowerbound, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n","        )\n","    \n","\n","    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch)"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:42.668448Z","iopub.execute_input":"2022-07-13T12:17:42.668919Z","iopub.status.idle":"2022-07-13T12:17:42.687370Z","shell.execute_reply.started":"2022-07-13T12:17:42.668869Z","shell.execute_reply":"2022-07-13T12:17:42.686156Z"},"trusted":true,"id":"IXbcYD9j1oPg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","\n","def show_plot(total):\n","    optimizer = torch.optim.SGD(torch.nn.Linear(2, 1).parameters(), lr=lr)\n","    scheduler = get_cosine_schedule_with_warmup(optimizer, total//10, total)\n","\n","    lrs = []\n","\n","    for i in range(total):\n","        optimizer.step()\n","        lrs.append(optimizer.param_groups[0][\"lr\"])\n","        scheduler.step()\n","\n","    plt.plot(range(total), lrs)\n","\n","    print(lrs[-5:])\n","    print(lrs[:5])\n","\n","total_steps = len(train_loader) * n_epochs\n","show_plot(total_steps)"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:42.689382Z","iopub.execute_input":"2022-07-13T12:17:42.689725Z","iopub.status.idle":"2022-07-13T12:17:46.593752Z","shell.execute_reply.started":"2022-07-13T12:17:42.689682Z","shell.execute_reply":"2022-07-13T12:17:46.592677Z"},"trusted":true,"id":"If-Y2i6L1oPh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train"],"metadata":{"id":"_HnFLZ572Q6s"}},{"cell_type":"code","source":["# %%script false --no-raise-error\n","\n","# modelSel = Classifier\n","# modelSel = ResNet18(ResBlock, 11)\n","modelSel = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False, num_classes=11)\n","\n","# Initialize a model, and put it on the device specified.\n","model = modelSel.to(device)\n","# model.load_state_dict(torch.load(f\"../input/ml2022hw3tmp/version7_best.ckpt\"))\n","\n","# For the classification task, we use cross-entropy as the measurement of performance.\n","criterion = nn.CrossEntropyLoss()\n","\n","# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay) \n","\n","total_steps = len(train_loader) * n_epochs\n","scheduler = get_cosine_schedule_with_warmup(optimizer, total_steps//10, total_steps)"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:46.595330Z","iopub.execute_input":"2022-07-13T12:17:46.595740Z","iopub.status.idle":"2022-07-13T12:17:46.625940Z","shell.execute_reply.started":"2022-07-13T12:17:46.595686Z","shell.execute_reply":"2022-07-13T12:17:46.624622Z"},"trusted":true,"id":"FiTPscG-1oPi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%script false --no-raise-error\n","\n","# Initialize trackers, these are not parameters and should not be changed\n","stale = 0\n","best_acc = 0\n","\n","for epoch in range(n_epochs):\n","\n","    # ---------- Training ----------\n","    # Make sure the model is in train mode before training.\n","    model.train()\n","\n","    # These are used to record information in training.\n","    train_loss = []\n","    train_accs = []\n","\n","    for batch in tqdm(train_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","        #imgs = imgs.half()\n","        #print(imgs.shape,labels.shape)\n","\n","        # Forward the data. (Make sure data and model are on the same device.)\n","        logits = model(imgs.to(device))\n","\n","        # Calculate the cross-entropy loss.\n","        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n","        loss = criterion(logits, labels.to(device))\n","\n","        # Gradients stored in the parameters in the previous step should be cleared out first.\n","        optimizer.zero_grad()\n","\n","        # Compute the gradients for parameters.\n","        loss.backward()\n","\n","        # Clip the gradient norms for stable training.\n","        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n","\n","        # Update the parameters with computed gradients.\n","        optimizer.step()\n","        \n","        # Update learning rate\n","        scheduler.step()\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        # Record the loss and accuracy.\n","        train_loss.append(loss.item())\n","        train_accs.append(acc)\n","        \n","    train_loss = sum(train_loss) / len(train_loss)\n","    train_acc = sum(train_accs) / len(train_accs)\n","\n","    # Print the information.\n","    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}, lr = {optimizer.param_groups[0]['lr']:.6f}\")\n","\n","    # ---------- Validation ----------\n","    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n","    model.eval()\n","\n","    # These are used to record information in validation.\n","    valid_loss = []\n","    valid_accs = []\n","\n","    # Iterate the validation set by batches.\n","    for batch in tqdm(valid_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","\n","        # We don't need gradient in validation.\n","        # Using torch.no_grad() accelerates the forward process.\n","        with torch.no_grad():\n","            logits = model(imgs.to(device))\n","\n","        # We can still compute the loss (but not the gradient).\n","        loss = criterion(logits, labels.to(device))\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        # Record the loss and accuracy.\n","        valid_loss.append(loss.item())\n","        valid_accs.append(acc)\n","        #break\n","\n","    # The average loss and accuracy for entire validation set is the average of the recorded values.\n","    valid_loss = sum(valid_loss) / len(valid_loss)\n","    valid_acc = sum(valid_accs) / len(valid_accs)\n","\n","    # update logs\n","    if valid_acc > best_acc:\n","        print(f\"[ Valid | {stale + 1:03d}/{epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n","    else:\n","        print(f\"[ Valid | {stale + 1:03d}/{epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","\n","\n","    # save models\n","    if valid_acc > best_acc:\n","        print(f\"Best model found at epoch {epoch + 1}, saving model {_exp_name}_best.ckpt\")\n","        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n","        best_acc = valid_acc\n","        stale = 0\n","    else:\n","        stale += 1\n","        if stale > patience:\n","            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n","            break\n","\n","torch.save(model.state_dict(), f\"{_exp_name}_model_last.ckpt\") "],"metadata":{"papermill":{"duration":32830.720158,"end_time":"2022-02-23T19:10:19.001001","exception":false,"start_time":"2022-02-23T10:03:08.280843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:17:46.627823Z","iopub.execute_input":"2022-07-13T12:17:46.628469Z","iopub.status.idle":"2022-07-13T12:17:46.658590Z","shell.execute_reply.started":"2022-07-13T12:17:46.628424Z","shell.execute_reply":"2022-07-13T12:17:46.656916Z"},"trusted":true,"id":"AE5g3GvJ1oPj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### DML"],"metadata":{"id":"YUSN7r-k1oPk"}},{"cell_type":"code","source":["%%script false --no-raise-error\n","\n","# Initialize a model, and put it on the device specified.\n","model1 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False, num_classes=11).to(device)\n","model2 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False, num_classes=11).to(device)\n","\n","# For the classification task, we use cross-entropy as the measurement of performance.\n","criterion = nn.CrossEntropyLoss()\n","\n","# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n","optimizer1 = torch.optim.Adam(model1.parameters(), lr=lr, weight_decay=weight_decay) \n","optimizer2 = torch.optim.Adam(model2.parameters(), lr=lr, weight_decay=weight_decay) \n","\n","total_steps = len(train_loader) * n_epochs\n","scheduler1 = get_cosine_schedule_with_warmup(optimizer1, total_steps//10, total_steps)\n","scheduler2 = get_cosine_schedule_with_warmup(optimizer2, total_steps//10, total_steps)"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:46.660555Z","iopub.execute_input":"2022-07-13T12:17:46.661049Z","iopub.status.idle":"2022-07-13T12:17:46.686238Z","shell.execute_reply.started":"2022-07-13T12:17:46.661011Z","shell.execute_reply":"2022-07-13T12:17:46.684523Z"},"trusted":true,"id":"5yOJa5PZ1oPl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%script false --no-raise-error\n","import torch.nn.functional as F\n","\n","def loss_fn_dml(input, target):\n","    return F.kl_div(F.log_softmax(input, dim=1),\n","                        F.softmax(target, dim=1),\n","                        log_target=False,\n","                        reduction='batchmean')"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:46.688444Z","iopub.execute_input":"2022-07-13T12:17:46.689402Z","iopub.status.idle":"2022-07-13T12:17:46.717786Z","shell.execute_reply.started":"2022-07-13T12:17:46.689344Z","shell.execute_reply":"2022-07-13T12:17:46.716557Z"},"trusted":true,"id":"zm3fB3CR1oPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%script false --no-raise-error\n","\n","# Initialize trackers, these are not parameters and should not be changed\n","stale = 0\n","best_acc = 0\n","\n","for epoch in range(n_epochs):\n","\n","    # ---------- Training ----------\n","    # Make sure the model is in train mode before training.\n","    model1.train()\n","    model2.train()\n","\n","    # These are used to record information in training.\n","    train_loss1 = []\n","    train_accs1 = []\n","    train_loss2 = []\n","    train_accs2 = []\n","\n","    for batch in tqdm(train_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","        # print(imgs.shape, labels.shape)\n","        \n","        # Forward the data. (Make sure data and model are on the same device.)\n","        logits1 = model1(imgs)\n","        logits2 = model2(imgs)\n","\n","        # Calculate the cross-entropy loss.\n","        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n","        loss1 = criterion(logits1, labels) + loss_fn_dml(logits1, logits2.detach())\n","        loss2 = criterion(logits2, labels) + loss_fn_dml(logits2, logits1.detach())\n","\n","        optimizer1.zero_grad() \n","        loss1.backward() \n","        grad_norm = nn.utils.clip_grad_norm_(model1.parameters(), max_norm=10)\n","        optimizer1.step() \n","        scheduler1.step()\n","        \n","        optimizer2.zero_grad() \n","        loss2.backward() \n","        grad_norm = nn.utils.clip_grad_norm_(model2.parameters(), max_norm=10)\n","        optimizer2.step() \n","        scheduler2.step()\n","\n","        # Compute the accuracy for current batch.\n","        acc1 = (logits1.argmax(dim=-1) == labels).float().mean()\n","        acc2 = (logits2.argmax(dim=-1) == labels).float().mean()\n","\n","        # Record the loss and accuracy.\n","        train_loss1.append(loss1.item())\n","        train_accs1.append(acc1)\n","        train_loss2.append(loss2.item())\n","        train_accs2.append(acc2)\n","        \n","    train_loss1 = sum(train_loss1) / len(train_loss1)\n","    train_acc1 = sum(train_accs1) / len(train_accs1)\n","    train_loss2 = sum(train_loss2) / len(train_loss2)\n","    train_acc2 = sum(train_accs2) / len(train_accs2)\n","\n","    # Print the information.\n","    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss1:.5f}|{train_loss2:.5f}, acc = {train_acc1:.5f}|{train_acc2:.5f}, lr = {optimizer1.param_groups[0]['lr']:.6f}|{optimizer2.param_groups[0]['lr']:.6f}\")\n","\n","    # ---------- Validation ----------\n","    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n","    model1.eval()\n","    model2.eval()\n","\n","    # These are used to record information in validation.\n","    valid_loss1 = []\n","    valid_accs1 = []\n","    valid_loss2 = []\n","    valid_accs2 = []\n","\n","    # Iterate the validation set by batches.\n","    for batch in tqdm(valid_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","        imgs = imgs.to(device)\n","        labels = labels.to(device)\n","\n","        # We don't need gradient in validation.\n","        # Using torch.no_grad() accelerates the forward process.\n","        with torch.no_grad():\n","            logits1 = model1(imgs)\n","            logits2 = model2(imgs)\n","\n","        # We can still compute the loss (but not the gradient).\n","        loss1 = criterion(logits1, labels)\n","        loss2 = criterion(logits2, labels)\n","\n","        # Compute the accuracy for current batch.\n","        acc1 = (logits1.argmax(dim=-1) == labels).float().mean()\n","        acc2 = (logits2.argmax(dim=-1) == labels).float().mean()\n","\n","        # Record the loss and accuracy.\n","        valid_loss1.append(loss1.item())\n","        valid_accs1.append(acc1)\n","        valid_loss2.append(loss2.item())\n","        valid_accs2.append(acc2)\n","\n","    # The average loss and accuracy for entire validation set is the average of the recorded values.\n","    valid_loss1 = sum(valid_loss1) / len(valid_loss1)\n","    valid_acc1 = sum(valid_accs1) / len(valid_accs1)\n","    valid_loss2 = sum(valid_loss2) / len(valid_loss2)\n","    valid_acc2 = sum(valid_accs2) / len(valid_accs2)\n","\n","    # update logs\n","    if max(valid_acc1, valid_acc2) > best_acc:\n","        print(f\"[ Valid | {stale + 1:03d}/{epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss1:.5f}|{valid_loss2:.5f}, acc = {valid_acc1:.5f}|{valid_acc2:.5f} -> best\")\n","    else:\n","        print(f\"[ Valid | {stale + 1:03d}/{epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss1:.5f}|{valid_loss2:.5f}, acc = {valid_acc1:.5f}|{valid_acc2:.5f}\")\n","\n","\n","    # save models\n","    if max(valid_acc1, valid_acc2) > best_acc:\n","        best_acc = max(valid_acc1, valid_acc2)\n","        if valid_acc1 == best_acc:\n","            print(f\"Best model found at epoch {epoch + 1}, saving model1 {_exp_name}_best.ckpt\")\n","            torch.save(model1.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n","            torch.save(model2.state_dict(), f\"{_exp_name}_other.ckpt\") # only save best to prevent output memory exceed error\n","        else:\n","            print(f\"Best model found at epoch {epoch + 1}, saving model2 {_exp_name}_best.ckpt\")\n","            torch.save(model2.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n","            torch.save(model1.state_dict(), f\"{_exp_name}_other.ckpt\") # only save best to prevent output memory exceed error\n","        \n","        stale = 0\n","    else:\n","        stale += 1\n","        if stale > patience:\n","            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n","            break\n","\n","torch.save(model1.state_dict(), f\"{_exp_name}_model1_last.ckpt\") \n","torch.save(model2.state_dict(), f\"{_exp_name}_model2_last.ckpt\") "],"metadata":{"papermill":{"duration":32830.720158,"end_time":"2022-02-23T19:10:19.001001","exception":false,"start_time":"2022-02-23T10:03:08.280843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:17:46.720239Z","iopub.execute_input":"2022-07-13T12:17:46.720535Z","iopub.status.idle":"2022-07-13T12:17:46.752933Z","shell.execute_reply.started":"2022-07-13T12:17:46.720503Z","shell.execute_reply":"2022-07-13T12:17:46.751069Z"},"trusted":true,"id":"9mHzXTXs1oPn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Testing and generate prediction CSV"],"metadata":{"papermill":{"duration":0.498773,"end_time":"2022-02-23T19:10:20.961802","exception":false,"start_time":"2022-02-23T19:10:20.463029","status":"completed"},"tags":[],"id":"Zkw8lNSe1oPo"}},{"cell_type":"code","source":["class FoodDatasetTest(Dataset):\n","    def __init__(self, paths, tfms, files=None, n=5):\n","        super(FoodDataset).__init__()\n","        self.paths = paths\n","        self.files = sorted([os.path.join(path,x) for path in paths for x in os.listdir(path) if x.endswith(\".jpg\")])\n","        if files != None:\n","            self.files = files\n","        print(f\"One {paths} sample\",self.files[0])\n","        self.transforms = tfms\n","        self.n = n\n","  \n","    def __len__(self):\n","        return len(self.files)\n","  \n","    def __getitem__(self,idx):\n","        fname = self.files[idx]\n","        im = Image.open(fname)\n","        im_test = self.transforms[0](im)\n","        \n","        im_train = []\n","        for _ in range(self.n):\n","            im_train.append(self.transforms[1](im))\n","            \n","        return im_test, im_train\n"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:46.756143Z","iopub.execute_input":"2022-07-13T12:17:46.756771Z","iopub.status.idle":"2022-07-13T12:17:46.770778Z","shell.execute_reply.started":"2022-07-13T12:17:46.756717Z","shell.execute_reply":"2022-07-13T12:17:46.768973Z"},"trusted":true,"id":"GEeMZOSZ1oPp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_set = FoodDatasetTest([os.path.join(_dataset_dir,\"test\")], tfms=[test_tfm, train_tfm], n=10)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"],"metadata":{"papermill":{"duration":0.493644,"end_time":"2022-02-23T19:10:19.985992","exception":false,"start_time":"2022-02-23T19:10:19.492348","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:17:46.772946Z","iopub.execute_input":"2022-07-13T12:17:46.773297Z","iopub.status.idle":"2022-07-13T12:17:47.086148Z","shell.execute_reply.started":"2022-07-13T12:17:46.773252Z","shell.execute_reply":"2022-07-13T12:17:47.085412Z"},"trusted":true,"id":"NLRAGv6f1oPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def avg_train_tfm_pred(model, imgs):\n","    logits = torch.zeros(imgs[0].shape[0], 11).to(device)\n","    \n","    with torch.no_grad():\n","        for img in imgs:\n","            logits += model(img.to(device))\n","        logits /= len(imgs)\n","        \n","    return logits"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:47.087264Z","iopub.execute_input":"2022-07-13T12:17:47.087845Z","iopub.status.idle":"2022-07-13T12:17:47.094458Z","shell.execute_reply.started":"2022-07-13T12:17:47.087791Z","shell.execute_reply":"2022-07-13T12:17:47.093194Z"},"trusted":true,"id":"qzJW7e3P1oPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model_best = ResNet18(ResBlock, 11).to(device)\n","model_best = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False, num_classes=11).to(device)\n","# model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\", map_location=device))\n","model_best.load_state_dict(torch.load(f\"resnet18_model_last.ckpt\", map_location=device))"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:17:58.439685Z","iopub.execute_input":"2022-07-13T12:17:58.440210Z","iopub.status.idle":"2022-07-13T12:18:02.080541Z","shell.execute_reply.started":"2022-07-13T12:17:58.440157Z","shell.execute_reply":"2022-07-13T12:18:02.079933Z"},"trusted":true,"id":"VT-dm_iU1oPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary(model_best, (batch_size, 3, 224, 224), device=device)"],"metadata":{"execution":{"iopub.status.busy":"2022-07-13T12:18:17.623234Z","iopub.execute_input":"2022-07-13T12:18:17.623657Z","iopub.status.idle":"2022-07-13T12:18:25.909317Z","shell.execute_reply.started":"2022-07-13T12:18:17.623626Z","shell.execute_reply":"2022-07-13T12:18:25.908486Z"},"trusted":true,"id":"vgdiKeuM1oPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_best.eval()\n","prediction = []\n","with torch.no_grad():\n","    for im_test, im_train in tqdm(test_loader):\n","        im_test = im_test.to(device)\n","        test_pred = model_best(im_test) + avg_train_tfm_pred(model_best, im_train)\n","        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n","        prediction += test_label.squeeze().tolist()"],"metadata":{"papermill":{"duration":49.157727,"end_time":"2022-02-23T19:11:10.61523","exception":false,"start_time":"2022-02-23T19:10:21.457503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:18:25.910869Z","iopub.execute_input":"2022-07-13T12:18:25.911911Z","iopub.status.idle":"2022-07-13T12:18:52.470992Z","shell.execute_reply.started":"2022-07-13T12:18:25.911863Z","shell.execute_reply":"2022-07-13T12:18:52.468741Z"},"trusted":true,"id":"fu7BMldD1oPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create test csv\n","def pad4(i):\n","    return \"0\"*(4-len(str(i)))+str(i)\n","df = pd.DataFrame()\n","df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n","df[\"Category\"] = prediction\n","df.to_csv(f\"submission_{best_acc}.csv\",index = False)"],"metadata":{"papermill":{"duration":0.554276,"end_time":"2022-02-23T19:11:11.870035","exception":false,"start_time":"2022-02-23T19:11:11.315759","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-13T12:18:52.474184Z","iopub.status.idle":"2022-07-13T12:18:52.474747Z","shell.execute_reply.started":"2022-07-13T12:18:52.474549Z","shell.execute_reply":"2022-07-13T12:18:52.474571Z"},"trusted":true,"id":"Of46I70a1oPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"puDKtaQR1oPu"},"execution_count":null,"outputs":[]}]}