{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MntmiANZCk2L"
      },
      "source": [
        "# GenAI HW9: Quick Summary of Lecture Video (演講影片快速摘要)\n",
        "## Objectives\n",
        "- ### Learn to quickly build applications related to speech recognition using existing APIs. (學習以現成的API快速搭建語音辨識相關的應用。)\n",
        "\n",
        "\n",
        "#### If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to ntu-gen-ai-2024-spring-ta@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voEioD2DCoeq"
      },
      "source": [
        "# Part1 - Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSccLtt234Pm"
      },
      "source": [
        "## The lecture video provided for this assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgHVz9WF4Vfp"
      },
      "source": [
        "(1) For ease of processing, it has already been converted to a MP3 file.\n",
        "\n",
        "(2) If you would like to view the original video, the link is here:\n",
        "\n",
        "- 李琳山教授 信號與人生 (2023)\n",
        "\n",
        "  - https://www.youtube.com/watch?v=MxoQV4M0jY8\n",
        "\n",
        "\n",
        "(3) Since the original lecture video is quite long, we have edited the segment from 1:43:24 to 2:00:49 to use for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdoLJZE33oCD"
      },
      "source": [
        "## Install all necessary packages and import them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HREsIZV33yDy"
      },
      "source": [
        "The following code block takes about **150** seconds to run, but it may vary slightly depending on the condition of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgL2wxdxCvA5",
        "outputId": "6d5f735e-8f92-4e39-f0a4-2c16bcec7038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-rl4656cz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-rl4656cz\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=c4ac4f30b6f6e5418449550ad4a736ff1684247b5164799818b598eb3ecd6ce9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9ypjzrcq/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Collecting srt\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=7a592dcc802ed40b1f69705dc2d5bd2239aa5f9c0a012a8711a32486ba8849a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n",
            "Successfully built srt\n",
            "Installing collected packages: srt\n",
            "Successfully installed srt-3.5.3\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-6.4.post2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from datetime) (2023.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime) (67.7.2)\n",
            "Installing collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-5.5 zope.interface-6.4.post2\n",
            "Collecting opencc\n",
            "  Downloading OpenCC-1.1.7-cp310-cp310-manylinux1_x86_64.whl (779 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.8/779.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencc\n",
            "Successfully installed opencc-1.1.7\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython) (67.7.2)\n",
            "Collecting jedi>=0.16 (from IPython)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.13)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.30.5-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.5\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.26.1-py3-none-any.whl (877 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.6/877.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.0)\n",
            "Collecting jiter<1,>=0.1.0 (from anthropic)\n",
            "  Downloading jiter-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.8/327.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.18.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Installing collected packages: jiter, anthropic\n",
            "Successfully installed anthropic-0.26.1 jiter-0.4.0\n"
          ]
        }
      ],
      "source": [
        "# Install packages.\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install srt\n",
        "!pip install datetime\n",
        "!pip install opencc\n",
        "!pip install datasets\n",
        "!pip install numpy\n",
        "!pip install soundfile\n",
        "!pip install IPython\n",
        "!pip install openai\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWqXz6C6omR9"
      },
      "source": [
        "The following code block takes about **5** seconds to run, but it may vary slightly depending on the condition of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFwSa_x6C53S"
      },
      "outputs": [],
      "source": [
        "# Import packages.\n",
        "\n",
        "import whisper\n",
        "import srt\n",
        "import datetime\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import pathlib\n",
        "import textwrap\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from opencc import OpenCC\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "import anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFY6VDAyeooa"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBROu_HfgF1J"
      },
      "source": [
        "The code block below takes about **10** seconds to run, although there might be some slight variation depending on the state of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "111ebffdf10d46b181c5284ff81a70c7",
            "a6b2021cf92d4b3eb7a755b5188ef081",
            "eec7687c9f3f4fdf9cab005dffd01619",
            "a24c013788c44e1693ea39d108e2923d",
            "2d64cc890e5349c29a5f446475c11993",
            "8b7a1b9f920a4f11bdb22c797d66bfd1",
            "dd95c7ab4dbf479fa4ce629736aa2879",
            "a3eb30a4c1144df991e507e2a55379da",
            "c1358ce7679e4ed4b2396ccb48fc63c0",
            "549faff1f8064c1c86981a36b6279766",
            "3029358340b248139f9fffa8431a0f4e",
            "ed5d72fd50b44e2f9d7808bd751c7ba9",
            "728f1a80d6cc4197a126ea0b8a50da5f",
            "bb0abf3d6285429a9243d5dfef8ce717",
            "6f5cbc4990d545a5a21644a3b9883450",
            "0694f31284274d85a4af9c69d6c86fb7",
            "c416f7e576c14c469863408bf81aeea7",
            "16909464160f4c4d9d658b06fcf60a79",
            "a958b534b9d44df79678ba2241beaa63",
            "2217b8c20efc48f8a85e1ec484c7f903",
            "bb006a5d26394e989381f69724095df3",
            "071fe271e0574f8d848832985bbb6a0d",
            "c0f43725845843b2982ddec349142aa8",
            "e0266e35b62e464795e33f6a58e7e80b",
            "b38b2fac25474ff892bdaa080026233d",
            "051802bc6fd14733bf04fd7e6aeaddc9",
            "8868a0f308c247b8b57161a422c49b1b",
            "34799a762213410ba71dfcf23b76a4ae",
            "bb90d47400404387bc0246e3581d76cf",
            "e8cf8569afe44b63b603d19bcd399308",
            "34e3829530e849adaa76f4b23eb2370b",
            "4af36759cdcb42508e49989b1d250e92",
            "35445aaf815d45d1a405da1ba395200a"
          ]
        },
        "id": "PAieqtY8evUJ",
        "outputId": "e5fe4ed3-b9ae-487e-d91f-6102b5313f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/305 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "111ebffdf10d46b181c5284ff81a70c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed5d72fd50b44e2f9d7808bd751c7ba9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0f43725845843b2982ddec349142aa8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load dataset. NTU-GenAI-2024-HW9.mp3\n",
        "dataset_name = \"kuanhuggingface/NTU-GenAI-2024-HW9\"\n",
        "dataset = load_dataset(dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1pN3dOGyrI-"
      },
      "source": [
        "The code block below takes about **15** seconds to run, although there might be some slight variation depending on the state of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E68E8Ej2isAX",
        "outputId": "27e38615-175f-4ebd-9864-0bedbb116718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now, we are going to transcribe the audio: 李琳山教授 信號與人生 (2023) (ntu-gen-ai-2024-hw9-16k.mp3).\n"
          ]
        }
      ],
      "source": [
        "# Prepare audio.\n",
        "input_audio = dataset[\"test\"][\"audio\"][0]\n",
        "input_audio_name = input_audio[\"path\"]\n",
        "input_audio_array = input_audio[\"array\"].astype(np.float32)\n",
        "sampling_rate = input_audio[\"sampling_rate\"]\n",
        "\n",
        "print(f\"Now, we are going to transcribe the audio: 李琳山教授 信號與人生 (2023) ({input_audio_name}).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxTn1CfzDCXy"
      },
      "source": [
        "# Part2 - Automatic Speech Recognition (ASR)\n",
        "The function \"speech_recognition\" aims to convert audio to subtitle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmWjjLUGC9z3"
      },
      "outputs": [],
      "source": [
        "def speech_recognition(model_name, input_audio, output_subtitle_path, decode_options, cache_dir=\"./\"):\n",
        "    '''\n",
        "        (1) Objective:\n",
        "            - This function aims to convert audio to subtitle.\n",
        "\n",
        "        (2) Arguments:\n",
        "\n",
        "            - model_name (str):\n",
        "                The name of the model. There are five model sizes, including tiny, base, small, medium, large-v3.\n",
        "                For example, you can use 'tiny', 'base', 'small', 'medium', 'large-v3' to specify the model name.\n",
        "                You can see 'https://github.com/openai/whisper' for more details.\n",
        "\n",
        "            - input_audio (Union[str, np.ndarray, torch.Tensor]):\n",
        "                The path to the audio file to open, or the audio waveform\n",
        "                - For example, if your input audio path is 'input.wav', you can use 'input.wav' to specify the input audio path.\n",
        "                - For example, if your input audio array is 'audio_array', you can use 'audio_array' to specify the input audio array.\n",
        "\n",
        "            - output_subtitle_path (str):\n",
        "                The path of the output subtitle file.\n",
        "                For example, if you want to save the subtitle file as 'output.srt', you can use 'output.srt' to specify the output subtitle path.\n",
        "\n",
        "            - decode_options (dict):\n",
        "                The options for decoding the audio file, including 'initial_prompt', 'prompt', 'prefix', 'temperature'.\n",
        "                - initial_prompt (str):\n",
        "                    Optional text to provide as a prompt for the first window. This can be used to provide, or\n",
        "                    \"prompt-engineer\" a context for transcription, e.g. custom vocabularies or proper nouns\n",
        "                    to make it more likely to predict those word correctly.\n",
        "                    Default: None.\n",
        "\n",
        "                You can see \"https://github.com/openai/whisper/blob/main/whisper/decoding.py\" and \"https://github.com/openai/whisper/blob/main/whisper/transcribe.py\"\n",
        "                for more details.\n",
        "\n",
        "                - temperature (float):\n",
        "                    The temperature for sampling from the model. Higher values mean more randomness.\n",
        "                    Default: 0.0\n",
        "\n",
        "            - cache_dir (str):\n",
        "                The path of the cache directory for saving the model.\n",
        "                For example, if you want to save the cache files in 'cache' directory, you can use 'cache' to specify the cache directory.\n",
        "                Default: './'\n",
        "\n",
        "        (3) Example:\n",
        "\n",
        "            - If you want to use the 'base' model to convert 'input.wav' to 'output.srt' and save the cache files in 'cache' directory,\n",
        "            you can call this function as follows:\n",
        "\n",
        "                speech_recognition(model_name='base', input_audio_path='input.wav', output_subtitle_path='output.srt', cache_dir='cache')\n",
        "    '''\n",
        "\n",
        "    # Record the start time.\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"=============== Loading Whisper-{model_name} ===============\")\n",
        "\n",
        "    # Load the model.\n",
        "    model = whisper.load_model(name=model_name, download_root=cache_dir)\n",
        "\n",
        "    print(f\"Begin to utilize Whisper-{model_name} to transcribe the audio.\")\n",
        "\n",
        "    # Transcribe the audio.\n",
        "    transcription = model.transcribe(audio=input_audio, language=decode_options[\"language\"], verbose=False,\n",
        "                                     initial_prompt=decode_options[\"initial_prompt\"], temperature=decode_options[\"temperature\"])\n",
        "\n",
        "    # Record the end time.\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f\"The process of speech recognition costs {end_time - start_time} seconds.\")\n",
        "\n",
        "    subtitles = []\n",
        "    # Convert the transcription to subtitle and iterate over the segments.\n",
        "    for i, segment in tqdm(enumerate(transcription[\"segments\"])):\n",
        "\n",
        "        # Convert the start time to subtitle format.\n",
        "        start_time = datetime.timedelta(seconds=segment[\"start\"])\n",
        "\n",
        "        # Convert the end time to subtitle format.\n",
        "        end_time = datetime.timedelta(seconds=segment[\"end\"])\n",
        "\n",
        "        # Get the subtitle text.\n",
        "        text = segment[\"text\"]\n",
        "\n",
        "        # Append the subtitle to the subtitle list.\n",
        "        subtitles.append(srt.Subtitle(index=i, start=start_time, end=end_time, content=text))\n",
        "\n",
        "    # Convert the subtitle list to subtitle content.\n",
        "    srt_content = srt.compose(subtitles)\n",
        "\n",
        "    print(f\"\\n=============== Saving the subtitle to {output_subtitle_path} ===============\")\n",
        "\n",
        "    # Save the subtitle content to the subtitle file.\n",
        "    with open(output_subtitle_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(srt_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3ZkyefXpvmh"
      },
      "source": [
        "In the following block, you can modify your desired parameters and the path of input file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UULEr1GpDAl6"
      },
      "outputs": [],
      "source": [
        "# @title Parameter Setting of Whisper { run: \"auto\" }\n",
        "\n",
        "''' In this block, you can modify your desired parameters and the path of input file. '''\n",
        "\n",
        "# The name of the model you want to use.\n",
        "# For example, you can use 'tiny', 'base', 'small', 'medium', 'large-v3' to specify the model name.\n",
        "# @markdown **model_name**: The name of the model you want to use.\n",
        "model_name = \"medium\" # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v3\"]\n",
        "\n",
        "# Define the suffix of the output file.\n",
        "# @markdown **suffix**: The output file name is \"output-{suffix}.* \", where .* is the file extention (.txt or .srt)\n",
        "suffix = \"信號與人生\" # @param {type: \"string\"}\n",
        "\n",
        "# Path to the output file.\n",
        "output_subtitle_path = f\"./output-{suffix}.srt\"\n",
        "\n",
        "# Path of the output raw text file from the SRT file.\n",
        "output_raw_text_path = f\"./output-{suffix}.txt\"\n",
        "\n",
        "# Path to the directory where the model and dataset will be cached.\n",
        "cache_dir = \"./\"\n",
        "\n",
        "# The language of the lecture video.\n",
        "# @markdown **language**: The language of the lecture video.\n",
        "language = \"zh\" # @param {type:\"string\"}\n",
        "\n",
        "# Optional text to provide as a prompt for the first window.\n",
        "# @markdown **initial_prompt**: Optional text to provide as a prompt for the first window.\n",
        "initial_prompt = \"請用繁體中文\" #@param {type:\"string\"}\n",
        "\n",
        "# The temperature for sampling from the model. Higher values mean more randomness.\n",
        "# @markdown  **temperature**: The temperature for sampling from the model. Higher values mean more randomness.\n",
        "temperature = 0 # @param {type:\"slider\", min:0, max:1, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBhoPRKR9S4w",
        "outputId": "da7982cd-8774-4aa6-c368-4c1c5fcbdf06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'language': 'zh', 'initial_prompt': '請用繁體中文', 'temperature': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Construct DecodingOptions\n",
        "decode_options = {\n",
        "    \"language\": language,\n",
        "    \"initial_prompt\": initial_prompt,\n",
        "    \"temperature\": temperature\n",
        "}\n",
        "decode_options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SfQ5Xn-fjya",
        "outputId": "c0f479fc-c490-4926-bdb7-c8448abb6f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting: (1) Model: whisper-medium (2) Language: zh (2) Initial Prompt: 請用繁體中文 (3) Temperature: 0\n",
            "Transcribe 李琳山教授 信號與人生 (2023)\n"
          ]
        }
      ],
      "source": [
        "# print message.\n",
        "message = \"Transcribe 李琳山教授 信號與人生 (2023)\"\n",
        "print(f\"Setting: (1) Model: whisper-{model_name} (2) Language: {language} (2) Initial Prompt: {initial_prompt} (3) Temperature: {temperature}\")\n",
        "print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxgZ2DNgpGlO"
      },
      "source": [
        "The code block below takes about **90 (240)** seconds to run when using the **base (medium)** model and **a T4 GPU**, although there might be some slight variation depending on the state of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOULGnw5RF6U",
        "outputId": "0453e01d-c30a-4a3c-d7a2-87208c7b18b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== Loading Whisper-medium ===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:24<00:00, 62.7MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin to utilize Whisper-medium to transcribe the audio.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104500/104500 [02:38<00:00, 657.35frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The process of speech recognition costs 201.150710105896 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "370it [00:00, 195255.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=============== Saving the subtitle to ./output-信號與人生.srt ===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Running ASR.\n",
        "speech_recognition(model_name=model_name, input_audio=input_audio_array, output_subtitle_path=output_subtitle_path, decode_options=decode_options, cache_dir=cache_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgmFtnti1qhU"
      },
      "source": [
        "You can check the result of automatic speech recognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeU54f5X1erZ",
        "outputId": "577bc429-b009-42a2-bdfa-2d5becfc0b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "00:00:00,000 --> 00:00:04,000\n",
            "每次說這個學問是做出來的\n",
            "\n",
            "2\n",
            "00:00:06,000 --> 00:00:08,000\n",
            "什麼意思?\n",
            "\n",
            "3\n",
            "00:00:08,000 --> 00:00:12,000\n",
            "要做才會獲得學問\n",
            "\n",
            "4\n",
            "00:00:13,000 --> 00:00:16,000\n",
            "你如果每天光是坐在那裡聽\n",
            "\n",
            "5\n",
            "00:00:17,000 --> 00:00:20,000\n",
            "學問很可能是左耳進右耳出的\n",
            "\n",
            "6\n",
            "00:00:21,000 --> 00:00:23,000\n",
            "你光是坐在那兒讀\n",
            "\n",
            "7\n",
            "00:00:23,000 --> 00:00:26,000\n",
            "學問可能從眼睛進入腦海之後就忘掉了\n",
            "\n",
            "8\n",
            "00:00:26,000 --> 00:00:29,000\n",
            "如何能夠學問在腦海裡面\n",
            "\n",
            "9\n",
            "00:00:31,000 --> 00:00:33,000\n",
            "真的變成你自己學問\n",
            "\n",
            "10\n",
            "00:00:33,000 --> 00:00:35,000\n",
            "就是要做\n",
            "\n",
            "11\n",
            "00:00:36,000 --> 00:00:39,000\n",
            "可能有很多同學有這個經驗\n",
            "\n",
            "12\n",
            "00:00:39,000 --> 00:00:41,000\n",
            "你如果去修某一門課\n",
            "\n",
            "13\n",
            "00:00:41,000 --> 00:00:44,000\n",
            "或者做某一個實驗\n",
            "\n",
            "14\n",
            "00:00:44,000 --> 00:00:47,000\n",
            "在期末就是要教一個final project\n",
            "\n",
            "15\n",
            "00:00:48,000 --> 00:00:50,000\n",
            "那個final project就是要你把\n",
            "\n",
            "16\n",
            "00:00:51,000 --> 00:00:53,000\n",
            "學到的很多東西\n",
            "\n",
            "17\n",
            "00:00:53,000 --> 00:00:56,000\n",
            "最後整合在你的final project裡面\n",
            "\n",
            "18\n",
            "00:00:56,000 --> 00:00:58,000\n",
            "最後做出來的時候\n",
            "\n",
            "19\n",
            "00:00:58,000 --> 00:01:00,000\n",
            "就是把它們都整合了\n",
            "\n",
            "20\n",
            "00:01:00,000 --> 00:01:02,000\n",
            "當你學期結束\n",
            "\n",
            "21\n",
            "00:01:02,000 --> 00:01:04,000\n",
            "真的把final project做完的時候\n",
            "\n",
            "22\n",
            "00:01:04,000 --> 00:01:05,000\n",
            "你會忽然發現\n",
            "\n",
            "23\n",
            "00:01:05,000 --> 00:01:07,000\n",
            "我真的學到很多東西\n",
            "\n",
            "24\n",
            "00:01:07,000 --> 00:01:10,000\n",
            "那就是做出來的學問\n",
            "\n",
            "25\n",
            "00:01:10,000 --> 00:01:13,000\n",
            "也許可以舉另外一個例子\n",
            "\n",
            "26\n",
            "00:01:13,000 --> 00:01:16,000\n",
            "就是你如果學了某一些很複雜的演算法\n",
            "\n",
            "27\n",
            "00:01:16,000 --> 00:01:17,000\n",
            "或者什麼\n",
            "\n",
            "28\n",
            "00:01:17,000 --> 00:01:21,000\n",
            "好像覺得那些不見得在你的腦海裡\n",
            "\n",
            "29\n",
            "00:01:21,000 --> 00:01:24,000\n",
            "可是後來老師出了個習題\n",
            "\n",
            "30\n",
            "00:01:24,000 --> 00:01:26,000\n",
            "那個習題教你寫一個很大的程式\n",
            "\n",
            "31\n",
            "00:01:26,000 --> 00:01:28,000\n",
            "要把所有東西都包進去\n",
            "\n",
            "32\n",
            "00:01:28,000 --> 00:01:31,000\n",
            "當你把這個程式寫完的時候你會發現\n",
            "\n",
            "33\n",
            "00:01:31,000 --> 00:01:35,000\n",
            "你忽然把演算法裡所有東西都弄通了\n",
            "\n",
            "34\n",
            "00:01:35,000 --> 00:01:38,000\n",
            "那就是學問是做出來的\n",
            "\n",
            "35\n",
            "00:01:38,000 --> 00:01:40,000\n",
            "所以我們永遠要記得\n",
            "\n",
            "36\n",
            "00:01:40,000 --> 00:01:44,000\n",
            "盡量多動手多做\n",
            "\n",
            "37\n",
            "00:01:44,000 --> 00:01:46,000\n",
            "在動手跟做的過程之中\n",
            "\n",
            "38\n",
            "00:01:46,000 --> 00:01:49,000\n",
            "學問才可以變成是自己的\n",
            "\n",
            "39\n",
            "00:01:49,000 --> 00:01:51,000\n",
            "同樣的情形就是說\n",
            "\n",
            "40\n",
            "00:01:51,000 --> 00:01:57,000\n",
            "很多時候這樣動手或者做的表現或者成績\n",
            "\n",
            "41\n",
            "00:01:57,000 --> 00:02:00,000\n",
            "沒有一個成績單上的數字\n",
            "\n",
            "42\n",
            "00:02:00,000 --> 00:02:03,000\n",
            "使得很多人覺得那不重要\n",
            "\n",
            "43\n",
            "00:02:03,000 --> 00:02:07,000\n",
            "很多人甚至覺得這門課要做final project\n",
            "\n",
            "44\n",
            "00:02:07,000 --> 00:02:09,000\n",
            "我就不修了太累了\n",
            "\n",
            "45\n",
            "00:02:09,000 --> 00:02:12,000\n",
            "或者說那門課需要怎麼樣怎麼樣太累\n",
            "\n",
            "46\n",
            "00:02:12,000 --> 00:02:13,000\n",
            "我就不要做了\n",
            "\n",
            "47\n",
            "00:02:13,000 --> 00:02:17,000\n",
            "而不知道其實那個才是讓你做的機會\n",
            "\n",
            "48\n",
            "00:02:17,000 --> 00:02:19,000\n",
            "然後可以學到最多\n",
            "\n",
            "49\n",
            "00:02:19,000 --> 00:02:24,000\n",
            "也就是說雖然很可能那麼辛苦的做很多事\n",
            "\n",
            "50\n",
            "00:02:24,000 --> 00:02:27,000\n",
            "沒有讓你獲得什麼具體成績\n",
            "\n",
            "51\n",
            "00:02:27,000 --> 00:02:30,000\n",
            "對你的overfitting可能沒有幫助\n",
            "\n",
            "52\n",
            "00:02:30,000 --> 00:02:33,000\n",
            "可是對你的全面學習是很有幫助\n",
            "\n",
            "53\n",
            "00:02:33,000 --> 00:02:35,000\n",
            "是該學的\n",
            "\n",
            "54\n",
            "00:02:35,000 --> 00:02:38,000\n",
            "那不要漏掉這些事\n",
            "\n",
            "55\n",
            "00:02:38,000 --> 00:02:41,000\n",
            "那這是我所說的\n",
            "\n",
            "56\n",
            "00:02:41,000 --> 00:02:46,000\n",
            "那這個課業內可以做的這些事\n",
            "\n",
            "57\n",
            "00:02:46,000 --> 00:02:50,000\n",
            "那剛才我們講到思考的時候\n",
            "\n",
            "58\n",
            "00:02:50,000 --> 00:02:52,000\n",
            "我覺得我漏掉一點\n",
            "\n",
            "59\n",
            "00:02:52,000 --> 00:02:56,000\n",
            "你如果修我的信號課你可能會發現\n",
            "\n",
            "60\n",
            "00:02:56,000 --> 00:03:00,000\n",
            "我上課沒講到一個數學式子的時候\n",
            "\n",
            "61\n",
            "00:03:00,000 --> 00:03:02,000\n",
            "我通常都不推他的\n",
            "\n",
            "62\n",
            "00:03:02,000 --> 00:03:06,000\n",
            "我是在解釋那個數學式子在說什麼話\n",
            "\n",
            "63\n",
            "00:03:06,000 --> 00:03:08,000\n",
            "同樣的呢\n",
            "\n",
            "64\n",
            "00:03:08,000 --> 00:03:10,000\n",
            "沒講到一個什麼什麼事情的時候\n",
            "\n",
            "65\n",
            "00:03:10,000 --> 00:03:14,000\n",
            "我通常就在解釋他在說什麼話\n",
            "\n",
            "66\n",
            "00:03:14,000 --> 00:03:16,000\n",
            "也就是說\n",
            "\n",
            "67\n",
            "00:03:16,000 --> 00:03:20,000\n",
            "我在講的就是我讀到特本那裡的時候\n",
            "\n",
            "68\n",
            "00:03:20,000 --> 00:03:22,000\n",
            "我心裡怎麼想的\n",
            "\n",
            "69\n",
            "00:03:22,000 --> 00:03:28,000\n",
            "也就是我在告訴同學如何這個讀書的時候\n",
            "\n",
            "70\n",
            "00:03:28,000 --> 00:03:32,000\n",
            "如何一面讀一面練習思考\n",
            "\n",
            "71\n",
            "00:03:32,000 --> 00:03:37,000\n",
            "那這個才是最重要的一件事\n",
            "\n",
            "72\n",
            "00:03:37,000 --> 00:03:40,000\n",
            "如何培養自己思考的能力\n",
            "\n",
            "73\n",
            "00:03:40,000 --> 00:03:42,000\n",
            "跟培養思考的習慣\n",
            "\n",
            "74\n",
            "00:03:42,000 --> 00:03:46,000\n",
            "我覺得最好的辦法就是讀書的時候\n",
            "\n",
            "75\n",
            "00:03:46,000 --> 00:03:50,000\n",
            "凡是讀到一個數學式子都去想一想\n",
            "\n",
            "76\n",
            "00:03:50,000 --> 00:03:53,000\n",
            "那個數學式子到底在說什麼\n",
            "\n",
            "77\n",
            "00:03:53,000 --> 00:03:57,000\n",
            "凡是讀到特本上講什麼就去想一想\n",
            "\n",
            "78\n",
            "00:03:57,000 --> 00:03:59,000\n",
            "那個到底在說什麼\n",
            "\n",
            "79\n",
            "00:03:59,000 --> 00:04:03,000\n",
            "你要真的了解他在說什麼的時候\n",
            "\n",
            "80\n",
            "00:04:03,000 --> 00:04:06,000\n",
            "你就用了很多思考的功夫\n",
            "\n",
            "81\n",
            "00:04:06,000 --> 00:04:09,000\n",
            "你就在練習自己思考的能力了\n",
            "\n",
            "82\n",
            "00:04:09,000 --> 00:04:14,000\n",
            "好 以上說的是課業內的部分\n",
            "\n",
            "83\n",
            "00:04:14,000 --> 00:04:18,000\n",
            "那當然除了課業內之外呢\n",
            "\n",
            "84\n",
            "00:04:18,000 --> 00:04:21,000\n",
            "還有一大堆是不在課業內的\n",
            "\n",
            "85\n",
            "00:04:21,000 --> 00:04:24,000\n",
            "那就是課業外的\n",
            "\n",
            "86\n",
            "00:04:24,000 --> 00:04:27,000\n",
            "課業外也有很多式的\n",
            "\n",
            "87\n",
            "00:04:27,000 --> 00:04:33,000\n",
            "那我們可以舉例來說\n",
            "\n",
            "88\n",
            "00:04:33,000 --> 00:04:38,000\n",
            "課業外有什麼可以學習的\n",
            "\n",
            "89\n",
            "00:04:38,000 --> 00:04:42,000\n",
            "那我通常把學習定義成為\n",
            "\n",
            "90\n",
            "00:04:42,000 --> 00:04:43,000\n",
            "什麼是學習\n",
            "\n",
            "91\n",
            "00:04:43,000 --> 00:04:49,000\n",
            "學習就是一種增長\n",
            "\n",
            "92\n",
            "00:04:49,000 --> 00:04:53,000\n",
            "一種進步\n",
            "\n",
            "93\n",
            "00:04:53,000 --> 00:04:57,000\n",
            "然後獲得快樂\n",
            "\n",
            "94\n",
            "00:04:57,000 --> 00:05:00,000\n",
            "這就是學習\n",
            "\n",
            "95\n",
            "00:05:00,000 --> 00:05:03,000\n",
            "所以即使是課業外的任何事情\n",
            "\n",
            "96\n",
            "00:05:03,000 --> 00:05:05,000\n",
            "只要你覺得是有增長的\n",
            "\n",
            "97\n",
            "00:05:05,000 --> 00:05:07,000\n",
            "是有進步的\n",
            "\n",
            "98\n",
            "00:05:07,000 --> 00:05:08,000\n",
            "讓你覺得快樂的\n",
            "\n",
            "99\n",
            "00:05:08,000 --> 00:05:12,000\n",
            "那應該就是值得學習的地方\n",
            "\n",
            "100\n",
            "00:05:12,000 --> 00:05:16,000\n",
            "那我們可以舉很多例子\n",
            "\n",
            "101\n",
            "00:05:16,000 --> 00:05:20,000\n",
            "譬如說很多同學喜歡打球\n",
            "\n",
            "102\n",
            "00:05:20,000 --> 00:05:22,000\n",
            "打球是不是學習\n",
            "\n",
            "103\n",
            "00:05:22,000 --> 00:05:24,000\n",
            "當然是\n",
            "\n",
            "104\n",
            "00:05:24,000 --> 00:05:26,000\n",
            "在打球中間有沒有增長\n",
            "\n",
            "105\n",
            "00:05:26,000 --> 00:05:27,000\n",
            "當然是\n",
            "\n",
            "106\n",
            "00:05:27,000 --> 00:05:30,000\n",
            "在打球中間有沒有增長\n",
            "\n",
            "107\n",
            "00:05:30,000 --> 00:05:31,000\n",
            "當然有增長\n",
            "\n",
            "108\n",
            "00:05:31,000 --> 00:05:35,000\n",
            "打球不只是對健康有增長\n",
            "\n",
            "109\n",
            "00:05:35,000 --> 00:05:39,000\n",
            "而且可能對於譬如說手腦協調\n",
            "\n",
            "110\n",
            "00:05:39,000 --> 00:05:41,000\n",
            "譬如說團隊精神\n",
            "\n",
            "111\n",
            "00:05:41,000 --> 00:05:44,000\n",
            "譬如說個人之間的互動\n",
            "\n",
            "112\n",
            "00:05:44,000 --> 00:05:45,000\n",
            "什麼可能都有幫助\n",
            "\n",
            "113\n",
            "00:05:45,000 --> 00:05:47,000\n",
            "所以打球當然是有增長的\n",
            "\n",
            "114\n",
            "00:05:47,000 --> 00:05:50,000\n",
            "那當然是很好的學習的機會\n",
            "\n",
            "115\n",
            "00:05:50,000 --> 00:05:52,000\n",
            "有人喜歡爬山\n",
            "\n",
            "116\n",
            "00:05:52,000 --> 00:05:54,000\n",
            "爬山是不是好的學習機會\n",
            "\n",
            "117\n",
            "00:05:54,000 --> 00:05:55,000\n",
            "當然是\n",
            "\n",
            "118\n",
            "00:05:55,000 --> 00:05:57,000\n",
            "這個我以前兩年前就講過很多\n",
            "\n",
            "119\n",
            "00:05:57,000 --> 00:05:59,000\n",
            "爬山可以學到很多的\n",
            "\n",
            "120\n",
            "00:05:59,000 --> 00:06:02,000\n",
            "那爬山當然是一種學習\n",
            "\n",
            "121\n",
            "00:06:02,000 --> 00:06:03,000\n",
            "有人說我不喜歡爬山\n",
            "\n",
            "122\n",
            "00:06:03,000 --> 00:06:05,000\n",
            "我去旅行好不好\n",
            "\n",
            "123\n",
            "00:06:05,000 --> 00:06:07,000\n",
            "旅行當然好\n",
            "\n",
            "124\n",
            "00:06:07,000 --> 00:06:09,000\n",
            "旅行可以增長見識\n",
            "\n",
            "125\n",
            "00:06:09,000 --> 00:06:11,000\n",
            "可以擴增事業\n",
            "\n",
            "126\n",
            "00:06:11,000 --> 00:06:13,000\n",
            "可以增加很多很多\n",
            "\n",
            "127\n",
            "00:06:13,000 --> 00:06:14,000\n",
            "當然是有進步的\n",
            "\n",
            "128\n",
            "00:06:14,000 --> 00:06:16,000\n",
            "所以當然是很好的學習\n",
            "\n",
            "129\n",
            "00:06:16,000 --> 00:06:20,000\n",
            "你凡是獲得快樂都是很好的事\n",
            "\n",
            "130\n",
            "00:06:20,000 --> 00:06:23,000\n",
            "那這些都值得下功夫去\n",
            "\n",
            "131\n",
            "00:06:23,000 --> 00:06:25,000\n",
            "把它看成是學習\n",
            "\n",
            "132\n",
            "00:06:25,000 --> 00:06:27,000\n",
            "都值得下功夫去做的\n",
            "\n",
            "133\n",
            "00:06:27,000 --> 00:06:29,000\n",
            "我們再講另外一系列\n",
            "\n",
            "134\n",
            "00:06:29,000 --> 00:06:30,000\n",
            "譬如說\n",
            "\n",
            "135\n",
            "00:06:30,000 --> 00:06:34,000\n",
            "有人說談戀愛是不是學習\n",
            "\n",
            "136\n",
            "00:06:34,000 --> 00:06:37,000\n",
            "談戀愛除了你在談戀愛上\n",
            "\n",
            "137\n",
            "00:06:37,000 --> 00:06:39,000\n",
            "會有收穫以外\n",
            "\n",
            "138\n",
            "00:06:39,000 --> 00:06:41,000\n",
            "本身也是有收穫的\n",
            "\n",
            "139\n",
            "00:06:41,000 --> 00:06:44,000\n",
            "因為讓你體驗到人跟人之間\n",
            "\n",
            "140\n",
            "00:06:44,000 --> 00:06:45,000\n",
            "的各種感覺\n",
            "\n",
            "141\n",
            "00:06:45,000 --> 00:06:48,000\n",
            "人跟人之間的各種期待等等\n",
            "\n",
            "142\n",
            "00:06:48,000 --> 00:06:50,000\n",
            "有沒有幫助\n",
            "\n",
            "143\n",
            "00:06:50,000 --> 00:06:52,000\n",
            "當然有幫助\n",
            "\n",
            "144\n",
            "00:06:52,000 --> 00:06:54,000\n",
            "對每一個人都是很好的學習\n",
            "\n",
            "145\n",
            "00:06:54,000 --> 00:06:57,000\n",
            "所以談戀愛當然是一件很好的事\n",
            "\n",
            "146\n",
            "00:06:57,000 --> 00:07:00,000\n",
            "有人會說那要靠緣分\n",
            "\n",
            "147\n",
            "00:07:00,000 --> 00:07:02,000\n",
            "沒有緣分沒有辦法\n",
            "\n",
            "148\n",
            "00:07:02,000 --> 00:07:03,000\n",
            "對不對\n",
            "\n",
            "149\n",
            "00:07:03,000 --> 00:07:04,000\n",
            "對\n",
            "\n",
            "150\n",
            "00:07:04,000 --> 00:07:06,000\n",
            "但是你不是一定要談戀愛嗎\n",
            "\n",
            "151\n",
            "00:07:06,000 --> 00:07:07,000\n",
            "你可以交朋友\n",
            "\n",
            "152\n",
            "00:07:07,000 --> 00:07:10,000\n",
            "交朋友是不是學習\n",
            "\n",
            "153\n",
            "00:07:10,000 --> 00:07:11,000\n",
            "當然是\n",
            "\n",
            "154\n",
            "00:07:11,000 --> 00:07:13,000\n",
            "交朋友也一樣\n",
            "\n",
            "155\n",
            "00:07:13,000 --> 00:07:16,000\n",
            "讓我們學到很多人際的互動\n",
            "\n",
            "156\n",
            "00:07:16,000 --> 00:07:20,000\n",
            "學到很多人跟人之間的溝通\n",
            "\n",
            "157\n",
            "00:07:20,000 --> 00:07:22,000\n",
            "人跟人之間的期待\n",
            "\n",
            "158\n",
            "00:07:22,000 --> 00:07:24,000\n",
            "人跟人之間的感覺\n",
            "\n",
            "159\n",
            "00:07:24,000 --> 00:07:26,000\n",
            "這都是交朋友之後學到的\n",
            "\n",
            "160\n",
            "00:07:26,000 --> 00:07:28,000\n",
            "對我們電機系的同學而言\n",
            "\n",
            "161\n",
            "00:07:28,000 --> 00:07:31,000\n",
            "你四周有一大群好同學\n",
            "\n",
            "162\n",
            "00:07:31,000 --> 00:07:34,000\n",
            "都是很好的交朋友的對象\n",
            "\n",
            "163\n",
            "00:07:34,000 --> 00:07:36,000\n",
            "你下一番功夫交朋友好不好\n",
            "\n",
            "164\n",
            "00:07:36,000 --> 00:07:37,000\n",
            "好\n",
            "\n",
            "165\n",
            "00:07:37,000 --> 00:07:40,000\n",
            "當然是有幫助的\n",
            "\n",
            "166\n",
            "00:07:40,000 --> 00:07:42,000\n",
            "另外當然我們可以舉很多\n",
            "\n",
            "167\n",
            "00:07:42,000 --> 00:07:44,000\n",
            "我們最現成的例子\n",
            "\n",
            "168\n",
            "00:07:44,000 --> 00:07:47,000\n",
            "譬如說我們的戲學會辦各種活動\n",
            "\n",
            "169\n",
            "00:07:47,000 --> 00:07:49,000\n",
            "那些活動有沒有幫助\n",
            "\n",
            "170\n",
            "00:07:49,000 --> 00:07:50,000\n",
            "當然有\n",
            "\n",
            "171\n",
            "00:07:50,000 --> 00:07:54,000\n",
            "我們舉例來講電業\n",
            "\n",
            "172\n",
            "00:07:54,000 --> 00:07:57,000\n",
            "你如果去參加某一個舞跳個舞\n",
            "\n",
            "173\n",
            "00:07:57,000 --> 00:08:00,000\n",
            "或者參加某個劇演個劇\n",
            "\n",
            "174\n",
            "00:08:00,000 --> 00:08:01,000\n",
            "有沒有幫助\n",
            "\n",
            "175\n",
            "00:08:01,000 --> 00:08:02,000\n",
            "當然有幫助\n",
            "\n",
            "176\n",
            "00:08:02,000 --> 00:08:05,000\n",
            "你在這中間一定發現有所增長\n",
            "\n",
            "177\n",
            "00:08:05,000 --> 00:08:06,000\n",
            "有所進步\n",
            "\n",
            "178\n",
            "00:08:06,000 --> 00:08:09,000\n",
            "那是為什麼有那麼多同學要去參加\n",
            "\n",
            "179\n",
            "00:08:09,000 --> 00:08:13,000\n",
            "就是因為發現那個確實是有增長有進步\n",
            "\n",
            "180\n",
            "00:08:13,000 --> 00:08:15,000\n",
            "有的人說\n",
            "\n",
            "181\n",
            "00:08:15,000 --> 00:08:17,000\n",
            "我不去跳那個舞\n",
            "\n",
            "182\n",
            "00:08:17,000 --> 00:08:20,000\n",
            "或者演那個劇\n",
            "\n",
            "183\n",
            "00:08:20,000 --> 00:08:22,000\n",
            "我做幕後的\n",
            "\n",
            "184\n",
            "00:08:22,000 --> 00:08:25,000\n",
            "譬如說是幕後的什麼規劃\n",
            "\n",
            "185\n",
            "00:08:25,000 --> 00:08:29,000\n",
            "或者說是什麼光舞的什麼軟體組\n",
            "\n",
            "186\n",
            "00:08:29,000 --> 00:08:32,000\n",
            "還是什麼服裝道具組\n",
            "\n",
            "187\n",
            "00:08:32,000 --> 00:08:33,000\n",
            "一樣\n",
            "\n",
            "188\n",
            "00:08:33,000 --> 00:08:36,000\n",
            "那個都是可以有獲得很多的增長\n",
            "\n",
            "189\n",
            "00:08:36,000 --> 00:08:37,000\n",
            "很多進步的\n",
            "\n",
            "190\n",
            "00:08:37,000 --> 00:08:39,000\n",
            "當然都是很有用的\n",
            "\n",
            "191\n",
            "00:08:39,000 --> 00:08:42,000\n",
            "都是很好的學習\n",
            "\n",
            "192\n",
            "00:08:42,000 --> 00:08:47,000\n",
            "那當然也包括電業以外的戲學會\n",
            "\n",
            "193\n",
            "00:08:47,000 --> 00:08:50,000\n",
            "其他的各種活動都一樣\n",
            "\n",
            "194\n",
            "00:08:50,000 --> 00:08:55,000\n",
            "也包括電機系以外的其他的校內\n",
            "\n",
            "195\n",
            "00:08:55,000 --> 00:08:59,000\n",
            "或者校外的各種活動幾乎都一樣\n",
            "\n",
            "196\n",
            "00:08:59,000 --> 00:09:02,000\n",
            "都可以讓人有所增長有所進步\n",
            "\n",
            "197\n",
            "00:09:02,000 --> 00:09:04,000\n",
            "都是很好的學習的機會\n",
            "\n",
            "198\n",
            "00:09:04,000 --> 00:09:06,000\n",
            "都是很好的學習\n",
            "\n",
            "199\n",
            "00:09:06,000 --> 00:09:10,000\n",
            "同樣的問題是這些東西都沒有考試\n",
            "\n",
            "200\n",
            "00:09:10,000 --> 00:09:12,000\n",
            "沒有成績\n",
            "\n",
            "201\n",
            "00:09:12,000 --> 00:09:14,000\n",
            "不能顯示在成績單上\n",
            "\n",
            "202\n",
            "00:09:14,000 --> 00:09:18,000\n",
            "因此對有一些同學會認為那個浪費時間\n",
            "\n",
            "203\n",
            "00:09:18,000 --> 00:09:20,000\n",
            "我不需要花時間去做那個\n",
            "\n",
            "204\n",
            "00:09:20,000 --> 00:09:24,000\n",
            "因為不影響我的overfitting的目標\n",
            "\n",
            "205\n",
            "00:09:24,000 --> 00:09:26,000\n",
            "裡面沒有這個嘛\n",
            "\n",
            "206\n",
            "00:09:26,000 --> 00:09:28,000\n",
            "具體成績沒有這些嘛\n",
            "\n",
            "207\n",
            "00:09:28,000 --> 00:09:30,000\n",
            "那不要這樣想\n",
            "\n",
            "208\n",
            "00:09:30,000 --> 00:09:33,000\n",
            "因為那些都非常的重要\n",
            "\n",
            "209\n",
            "00:09:33,000 --> 00:09:36,000\n",
            "都對你發展非常的重要\n",
            "\n",
            "210\n",
            "00:09:36,000 --> 00:09:39,000\n",
            "那我們說電機工程\n",
            "\n",
            "211\n",
            "00:09:39,000 --> 00:09:41,000\n",
            "今天的電機工程\n",
            "\n",
            "212\n",
            "00:09:41,000 --> 00:09:44,000\n",
            "很少什麼事情自己一個人可以做成功的\n",
            "\n",
            "213\n",
            "00:09:44,000 --> 00:09:47,000\n",
            "你必須跟很多人一起\n",
            "\n",
            "214\n",
            "00:09:47,000 --> 00:09:50,000\n",
            "才可能做成功一個非常重要的\n",
            "\n",
            "215\n",
            "00:09:50,000 --> 00:09:52,000\n",
            "有意義的工作\n",
            "\n",
            "216\n",
            "00:09:52,000 --> 00:09:55,000\n",
            "那當你跟一群人在一起做的時候\n",
            "\n",
            "217\n",
            "00:09:55,000 --> 00:09:59,000\n",
            "你必須學會如何進入一個團隊\n",
            "\n",
            "218\n",
            "00:09:59,000 --> 00:10:03,000\n",
            "從邊緣開始慢慢進入核心\n",
            "\n",
            "219\n",
            "00:10:03,000 --> 00:10:06,000\n",
            "從底層開始慢慢變成leader\n",
            "\n",
            "220\n",
            "00:10:06,000 --> 00:10:09,000\n",
            "然後如何可以推動你想做的事\n",
            "\n",
            "221\n",
            "00:10:09,000 --> 00:10:13,000\n",
            "如何變成可以做到你想做的事等等\n",
            "\n",
            "222\n",
            "00:10:13,000 --> 00:10:15,000\n",
            "這些都是很重要的\n",
            "\n",
            "223\n",
            "00:10:15,000 --> 00:10:18,000\n",
            "那我們通常稱這些東西\n",
            "\n",
            "224\n",
            "00:10:18,000 --> 00:10:21,000\n",
            "是所謂的soft skills\n",
            "\n",
            "225\n",
            "00:10:21,000 --> 00:10:24,000\n",
            "也就是軟實力\n",
            "\n",
            "226\n",
            "00:10:24,000 --> 00:10:30,000\n",
            "所謂軟實力就是硬實力以外的軟實力\n",
            "\n",
            "227\n",
            "00:10:30,000 --> 00:10:34,000\n",
            "硬實力是說你電子學的功力\n",
            "\n",
            "228\n",
            "00:10:34,000 --> 00:10:36,000\n",
            "數學的功力\n",
            "\n",
            "229\n",
            "00:10:36,000 --> 00:10:40,000\n",
            "這個城市能力這種是硬實力\n",
            "\n",
            "230\n",
            "00:10:40,000 --> 00:10:45,000\n",
            "軟實力我們主要就是講各種人際之間的\n",
            "\n",
            "231\n",
            "00:10:45,000 --> 00:10:49,000\n",
            "在人跟人之間的各種能力\n",
            "\n",
            "232\n",
            "00:10:49,000 --> 00:10:54,000\n",
            "包括溝通能力協調能力交朋友的能力\n",
            "\n",
            "233\n",
            "00:10:54,000 --> 00:10:59,000\n",
            "說服人的能力團隊精神領導能力等等\n",
            "\n",
            "234\n",
            "00:10:59,000 --> 00:11:02,000\n",
            "那些就是所謂的soft skills\n",
            "\n",
            "235\n",
            "00:11:02,000 --> 00:11:04,000\n",
            "重要不重要重要\n",
            "\n",
            "236\n",
            "00:11:04,000 --> 00:11:07,000\n",
            "你看到任何一個成功的電機工程師\n",
            "\n",
            "237\n",
            "00:11:07,000 --> 00:11:09,000\n",
            "他都有一堆這種\n",
            "\n",
            "238\n",
            "00:11:09,000 --> 00:11:13,000\n",
            "這個才是他成功的一個非常重要的關鍵\n",
            "\n",
            "239\n",
            "00:11:13,000 --> 00:11:15,000\n",
            "這種東西怎麼來\n",
            "\n",
            "240\n",
            "00:11:15,000 --> 00:11:18,000\n",
            "我們剛才講的各種課業外的\n",
            "\n",
            "241\n",
            "00:11:18,000 --> 00:11:20,000\n",
            "各種學習增長的機會\n",
            "\n",
            "242\n",
            "00:11:20,000 --> 00:11:26,000\n",
            "都可以幫助一個人塑造他的soft skills\n",
            "\n",
            "243\n",
            "00:11:26,000 --> 00:11:30,000\n",
            "是有少數人的這些soft skills是天生的\n",
            "\n",
            "244\n",
            "00:11:30,000 --> 00:11:31,000\n",
            "他天生就厲害\n",
            "\n",
            "245\n",
            "00:11:31,000 --> 00:11:32,000\n",
            "有沒有\n",
            "\n",
            "246\n",
            "00:11:32,000 --> 00:11:33,000\n",
            "有\n",
            "\n",
            "247\n",
            "00:11:33,000 --> 00:11:35,000\n",
            "但這種人畢竟沒那麼多\n",
            "\n",
            "248\n",
            "00:11:35,000 --> 00:11:37,000\n",
            "對很多人而言\n",
            "\n",
            "249\n",
            "00:11:37,000 --> 00:11:42,000\n",
            "他的soft skills是自己努力慢慢培養起來的\n",
            "\n",
            "250\n",
            "00:11:42,000 --> 00:11:45,000\n",
            "我剛才一開始前面講的那一段\n",
            "\n",
            "251\n",
            "00:11:45,000 --> 00:11:49,000\n",
            "我說我在進台大電機系以前\n",
            "\n",
            "252\n",
            "00:11:49,000 --> 00:11:51,000\n",
            "我幾乎不會交朋友\n",
            "\n",
            "253\n",
            "00:11:51,000 --> 00:11:53,000\n",
            "我不太會說話\n",
            "\n",
            "254\n",
            "00:11:53,000 --> 00:11:57,000\n",
            "我在讀大學的四年裡面改變我自己\n",
            "\n",
            "255\n",
            "00:11:57,000 --> 00:12:02,000\n",
            "讓我變成有很多這方面的能力的人\n",
            "\n",
            "256\n",
            "00:12:02,000 --> 00:12:06,000\n",
            "其實最重要就是我的很多soft skills\n",
            "\n",
            "257\n",
            "00:12:06,000 --> 00:12:07,000\n",
            "都是我自己培養\n",
            "\n",
            "258\n",
            "00:12:07,000 --> 00:12:10,000\n",
            "在讀台大電機系的四年裡面\n",
            "\n",
            "259\n",
            "00:12:10,000 --> 00:12:14,000\n",
            "獲得的非常多這方面的收穫的\n",
            "\n",
            "260\n",
            "00:12:14,000 --> 00:12:18,000\n",
            "那是為什麼我每次都要強調\n",
            "\n",
            "261\n",
            "00:12:18,000 --> 00:12:21,000\n",
            "這個東西有多麼重要\n",
            "\n",
            "262\n",
            "00:12:21,000 --> 00:12:27,000\n",
            "我之前曾經在幾年前的這個\n",
            "\n",
            "263\n",
            "00:12:27,000 --> 00:12:31,000\n",
            "信號與人生裡面有說到這一件事\n",
            "\n",
            "264\n",
            "00:12:31,000 --> 00:12:33,000\n",
            "我現在不要重複\n",
            "\n",
            "265\n",
            "00:12:33,000 --> 00:12:36,000\n",
            "但是我簡單的summarize\n",
            "\n",
            "266\n",
            "00:12:36,000 --> 00:12:42,000\n",
            "我說我們電機系的電機工程師的\n",
            "\n",
            "267\n",
            "00:12:42,000 --> 00:12:45,000\n",
            "一生career的發展\n",
            "\n",
            "268\n",
            "00:12:45,000 --> 00:12:48,000\n",
            "黃金實在是在什麼時候\n",
            "\n",
            "269\n",
            "00:12:48,000 --> 00:12:52,000\n",
            "我認為是在35歲到55歲\n",
            "\n",
            "270\n",
            "00:12:52,000 --> 00:12:56,000\n",
            "這20年是我們的黃金時代\n",
            "\n",
            "271\n",
            "00:12:56,000 --> 00:12:58,000\n",
            "在這以前當然更好\n",
            "\n",
            "272\n",
            "00:12:58,000 --> 00:13:01,000\n",
            "只是說可能各方面尚未具備\n",
            "\n",
            "273\n",
            "00:13:01,000 --> 00:13:03,000\n",
            "還沒有完全訓練的好\n",
            "\n",
            "274\n",
            "00:13:03,000 --> 00:13:05,000\n",
            "在這以後是最好的\n",
            "\n",
            "275\n",
            "00:13:05,000 --> 00:13:10,000\n",
            "這以後年紀大了難免有一些要打個折扣等等\n",
            "\n",
            "276\n",
            "00:13:10,000 --> 00:13:13,000\n",
            "就這裡面我們看到\n",
            "\n",
            "277\n",
            "00:13:13,000 --> 00:13:15,000\n",
            "我們的電機系的畢業的同學\n",
            "\n",
            "278\n",
            "00:13:15,000 --> 00:13:18,000\n",
            "過去有幾千人畢業我都看到\n",
            "\n",
            "279\n",
            "00:13:18,000 --> 00:13:22,000\n",
            "我覺得有的人的發展是像這樣\n",
            "\n",
            "280\n",
            "00:13:22,000 --> 00:13:24,000\n",
            "有一定的斜率\n",
            "\n",
            "281\n",
            "00:13:24,000 --> 00:13:28,000\n",
            "但到某一個階段它會慢慢saturate\n",
            "\n",
            "282\n",
            "00:13:28,000 --> 00:13:31,000\n",
            "有的人也許開始向上比較晚\n",
            "\n",
            "283\n",
            "00:13:31,000 --> 00:13:33,000\n",
            "但它斜率比較高\n",
            "\n",
            "284\n",
            "00:13:33,000 --> 00:13:38,000\n",
            "它最後會saturate在比較高的地方\n",
            "\n",
            "285\n",
            "00:13:38,000 --> 00:13:41,000\n",
            "也有的人也許開始的比較快\n",
            "\n",
            "286\n",
            "00:13:41,000 --> 00:13:44,000\n",
            "但是後來會overshoot之後\n",
            "\n",
            "287\n",
            "00:13:44,000 --> 00:13:46,000\n",
            "會開始收斂在比較低的地方等等\n",
            "\n",
            "288\n",
            "00:13:46,000 --> 00:13:48,000\n",
            "每一個人都不一樣\n",
            "\n",
            "289\n",
            "00:13:48,000 --> 00:13:50,000\n",
            "但是當然也有一種人\n",
            "\n",
            "290\n",
            "00:13:50,000 --> 00:13:54,000\n",
            "你會看到他一直向上走\n",
            "\n",
            "291\n",
            "00:13:54,000 --> 00:13:58,000\n",
            "完全沒有saturate\n",
            "\n",
            "292\n",
            "00:13:58,000 --> 00:14:01,000\n",
            "這些人這些差別在哪裡\n",
            "\n",
            "293\n",
            "00:14:01,000 --> 00:14:04,000\n",
            "這些東西差別在哪裡\n",
            "\n",
            "294\n",
            "00:14:04,000 --> 00:14:06,000\n",
            "我以前已經說過這件事\n",
            "\n",
            "295\n",
            "00:14:06,000 --> 00:14:08,000\n",
            "我不要多重複\n",
            "\n",
            "296\n",
            "00:14:08,000 --> 00:14:11,000\n",
            "我說最主要因素有四個\n",
            "\n",
            "297\n",
            "00:14:11,000 --> 00:14:18,000\n",
            "實力、努力、大智\n",
            "\n",
            "298\n",
            "00:14:18,000 --> 00:14:23,000\n",
            "跟self skill這四件事情\n",
            "\n",
            "299\n",
            "00:14:23,000 --> 00:14:29,000\n",
            "我認為真正影響這個的\n",
            "\n",
            "300\n",
            "00:14:29,000 --> 00:14:32,000\n",
            "不是因為電子學考得好不好\n",
            "\n",
            "301\n",
            "00:14:32,000 --> 00:14:35,000\n",
            "不是因為信號與系統念得好不好\n",
            "\n",
            "302\n",
            "00:14:35,000 --> 00:14:37,000\n",
            "也就是我剛才講\n",
            "\n",
            "303\n",
            "00:14:37,000 --> 00:14:39,000\n",
            "你把每一門必修課\n",
            "\n",
            "304\n",
            "00:14:39,000 --> 00:14:41,000\n",
            "當成是單一跑道\n",
            "\n",
            "305\n",
            "00:14:41,000 --> 00:14:43,000\n",
            "跑到第一名並不表示怎樣\n",
            "\n",
            "306\n",
            "00:14:43,000 --> 00:14:45,000\n",
            "我們最後不看那個的\n",
            "\n",
            "307\n",
            "00:14:45,000 --> 00:14:47,000\n",
            "最後看的是這個\n",
            "\n",
            "308\n",
            "00:14:47,000 --> 00:14:49,000\n",
            "這個是怎麼樣影響\n",
            "\n",
            "309\n",
            "00:14:49,000 --> 00:14:51,000\n",
            "我認為是這四件事\n",
            "\n",
            "310\n",
            "00:14:51,000 --> 00:14:55,000\n",
            "就是實力、努力、大智跟self skills\n",
            "\n",
            "311\n",
            "00:14:55,000 --> 00:14:57,000\n",
            "這四件事裡面\n",
            "\n",
            "312\n",
            "00:14:57,000 --> 00:14:59,000\n",
            "我們現在可以summarize\n",
            "\n",
            "313\n",
            "00:14:59,000 --> 00:15:00,000\n",
            "我剛才講的\n",
            "\n",
            "314\n",
            "00:15:00,000 --> 00:15:02,000\n",
            "什麼是實力\n",
            "\n",
            "315\n",
            "00:15:02,000 --> 00:15:05,000\n",
            "實力就是所有的這些\n",
            "\n",
            "316\n",
            "00:15:05,000 --> 00:15:07,000\n",
            "我們電機工程的專業領域裡面\n",
            "\n",
            "317\n",
            "00:15:07,000 --> 00:15:09,000\n",
            "各種東西的實力\n",
            "\n",
            "318\n",
            "00:15:09,000 --> 00:15:11,000\n",
            "實力怎麼厲害法\n",
            "\n",
            "319\n",
            "00:15:11,000 --> 00:15:13,000\n",
            "就是我剛才講的\n",
            "\n",
            "320\n",
            "00:15:13,000 --> 00:15:16,000\n",
            "你如果都是在做全面的學習的話\n",
            "\n",
            "321\n",
            "00:15:16,000 --> 00:15:18,000\n",
            "你就會學到各種該學到的\n",
            "\n",
            "322\n",
            "00:15:18,000 --> 00:15:20,000\n",
            "最後你的實力就是很強的\n",
            "\n",
            "323\n",
            "00:15:20,000 --> 00:15:25,000\n",
            "所以實力最主要就是不要overfitting\n",
            "\n",
            "324\n",
            "00:15:25,000 --> 00:15:27,000\n",
            "要盡量都做\n",
            "\n",
            "325\n",
            "00:15:27,000 --> 00:15:31,000\n",
            "學到該學的全面的學習\n",
            "\n",
            "326\n",
            "00:15:31,000 --> 00:15:33,000\n",
            "努力是沒有疑問\n",
            "\n",
            "327\n",
            "00:15:33,000 --> 00:15:34,000\n",
            "每一個人都了解\n",
            "\n",
            "328\n",
            "00:15:34,000 --> 00:15:36,000\n",
            "確實我們可以看到\n",
            "\n",
            "329\n",
            "00:15:36,000 --> 00:15:38,000\n",
            "一個人在未來的幾十年裡面\n",
            "\n",
            "330\n",
            "00:15:38,000 --> 00:15:40,000\n",
            "有的人他一直努力\n",
            "\n",
            "331\n",
            "00:15:40,000 --> 00:15:42,000\n",
            "有的人慢慢不太努力等等\n",
            "\n",
            "332\n",
            "00:15:42,000 --> 00:15:44,000\n",
            "這個是有明顯差別的\n",
            "\n",
            "333\n",
            "00:15:44,000 --> 00:15:46,000\n",
            "那self skills我剛才已經講了\n",
            "\n",
            "334\n",
            "00:15:46,000 --> 00:15:50,000\n",
            "就是很多我們平常沒有算成績\n",
            "\n",
            "335\n",
            "00:15:50,000 --> 00:15:52,000\n",
            "覺得大家不重視的事情\n",
            "\n",
            "336\n",
            "00:15:52,000 --> 00:15:54,000\n",
            "其實它常常是很重要的\n",
            "\n",
            "337\n",
            "00:15:54,000 --> 00:15:56,000\n",
            "你如果好好的\n",
            "\n",
            "338\n",
            "00:15:56,000 --> 00:16:00,000\n",
            "多在各種課業外的事情上\n",
            "\n",
            "339\n",
            "00:16:00,000 --> 00:16:02,000\n",
            "增長進步的話\n",
            "\n",
            "340\n",
            "00:16:02,000 --> 00:16:04,000\n",
            "你這些東西會很強\n",
            "\n",
            "341\n",
            "00:16:04,000 --> 00:16:06,000\n",
            "你會很厲害的\n",
            "\n",
            "342\n",
            "00:16:06,000 --> 00:16:08,000\n",
            "當然對少數人而言\n",
            "\n",
            "343\n",
            "00:16:08,000 --> 00:16:09,000\n",
            "他天生就有\n",
            "\n",
            "344\n",
            "00:16:09,000 --> 00:16:10,000\n",
            "他可能不需要\n",
            "\n",
            "345\n",
            "00:16:10,000 --> 00:16:12,000\n",
            "這是每一個人不一樣的\n",
            "\n",
            "346\n",
            "00:16:12,000 --> 00:16:14,000\n",
            "那這三個我都提過了\n",
            "\n",
            "347\n",
            "00:16:14,000 --> 00:16:16,000\n",
            "那麼大致我還沒有提\n",
            "\n",
            "348\n",
            "00:16:16,000 --> 00:16:18,000\n",
            "其實大致沒有什麼要特別說的\n",
            "\n",
            "349\n",
            "00:16:18,000 --> 00:16:21,000\n",
            "那應該就是我剛才前面有講過\n",
            "\n",
            "350\n",
            "00:16:21,000 --> 00:16:26,000\n",
            "就是每一個人可以有你自己的長程目標\n",
            "\n",
            "351\n",
            "00:16:26,000 --> 00:16:29,000\n",
            "那有的人本來就有了\n",
            "\n",
            "352\n",
            "00:16:29,000 --> 00:16:32,000\n",
            "有的人也許我平常沒有想過\n",
            "\n",
            "353\n",
            "00:16:32,000 --> 00:16:37,000\n",
            "那你可以在適當時機開始想\n",
            "\n",
            "354\n",
            "00:16:37,000 --> 00:16:40,000\n",
            "我有沒有想要做什麼事情\n",
            "\n",
            "355\n",
            "00:16:40,000 --> 00:16:43,000\n",
            "哪些事情可能是我的長程目標\n",
            "\n",
            "356\n",
            "00:16:43,000 --> 00:16:48,000\n",
            "我希望最後讓我花個5年10年\n",
            "\n",
            "357\n",
            "00:16:48,000 --> 00:16:50,000\n",
            "15年或者更長\n",
            "\n",
            "358\n",
            "00:16:50,000 --> 00:16:52,000\n",
            "我把我的很多的努力\n",
            "\n",
            "359\n",
            "00:16:52,000 --> 00:16:55,000\n",
            "都來把某一些事情做得非常漂亮\n",
            "\n",
            "360\n",
            "00:16:55,000 --> 00:16:57,000\n",
            "那是我很想做的事\n",
            "\n",
            "361\n",
            "00:16:57,000 --> 00:17:00,000\n",
            "那就是長程目標\n",
            "\n",
            "362\n",
            "00:17:00,000 --> 00:17:04,000\n",
            "如果我覺得做那些事情會讓我非常的\n",
            "\n",
            "363\n",
            "00:17:04,000 --> 00:17:05,000\n",
            "覺得有意義\n",
            "\n",
            "364\n",
            "00:17:05,000 --> 00:17:07,000\n",
            "願意花功夫下去做的\n",
            "\n",
            "365\n",
            "00:17:07,000 --> 00:17:09,000\n",
            "那就是我的長程目標\n",
            "\n",
            "366\n",
            "00:17:09,000 --> 00:17:12,000\n",
            "那有的人如果可以想出這個來的話\n",
            "\n",
            "367\n",
            "00:17:12,000 --> 00:17:15,000\n",
            "那就是他的大致\n",
            "\n",
            "368\n",
            "00:17:15,000 --> 00:17:17,000\n",
            "那越是有這種大致的人\n",
            "\n",
            "369\n",
            "00:17:17,000 --> 00:17:20,000\n",
            "也比較容易向上衝\n",
            "\n",
            "370\n",
            "00:17:20,000 --> 00:17:25,000\n",
            "那我感覺起來真正影響的就是這四件事\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "''' Open the SRT file and read its content.\n",
        "The format of SRT is:\n",
        "\n",
        "[Index]\n",
        "[Begin time] (hour:minute:second) --> [End time] (hour:minute:second)\n",
        "[Transcription]\n",
        "\n",
        "'''\n",
        "\n",
        "with open(output_subtitle_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7JcN-kUDE_g"
      },
      "source": [
        "# Part3 - Preprocess the results of automatic speech recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2R40faVDShf"
      },
      "outputs": [],
      "source": [
        "def extract_and_save_text(srt_filename, output_filename):\n",
        "\n",
        "    '''\n",
        "    (1) Objective:\n",
        "        - This function extracts the text from an SRT file and saves it to a new text file.\n",
        "        - It also converts the Simplified Chinese to Traditional Chinese.\n",
        "\n",
        "    (2) Arguments:\n",
        "\n",
        "        - srt_filename: The path to the SRT file.\n",
        "\n",
        "        - output_filename: The name of the output text file.\n",
        "\n",
        "    (3) Example:\n",
        "        - If your SRT file is named 'subtitle.srt' and you want to save the extracted text to a file named 'output.txt', you can use the function like this:\n",
        "            extract_and_save_text('subtitle.srt', 'output.txt')\n",
        "\n",
        "    '''\n",
        "\n",
        "    # Open the SRT file and read its content.\n",
        "    with open(srt_filename, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Use regular expression to remove the timecode.\n",
        "    pure_text = re.sub(r'\\d+\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n', '', content)\n",
        "\n",
        "    # Remove the empty lines.\n",
        "    pure_text = re.sub(r'\\n\\n+', '\\n', pure_text)\n",
        "\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    pure_text_conversion = cc.convert(pure_text)\n",
        "\n",
        "    # Write the extracted text to a new file.\n",
        "    with open(output_filename, 'w', encoding='utf-8') as output_file:\n",
        "        output_file.write(pure_text_conversion)\n",
        "\n",
        "    print(f'Extracted text has been saved to {output_filename}.\\n\\n')\n",
        "\n",
        "    return pure_text_conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWDl1vuADd0e"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, max_length):\n",
        "    \"\"\"\n",
        "    (1) Objective:\n",
        "        - This function is used to split a long string into smaller strings of a specified length.\n",
        "\n",
        "    (2) Arguments:\n",
        "        - text: str, the long string to be split.\n",
        "        - max_length: int, the maximum length of each smaller string.\n",
        "\n",
        "    (3) Returns:\n",
        "        - split_text: list, a list of smaller strings.\n",
        "\n",
        "    (3) Example:\n",
        "        - If you want to split a string named \"long_string\" into smaller strings of length 100, you can use the function like this:\n",
        "            chunk_text(long_string, 100)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    return textwrap.wrap(text, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO01S41pOsSP"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired parameters and the path of input file. '''\n",
        "\n",
        "# # The length of the text chunks.\n",
        "chunk_length = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-PpbkoS-5bI",
        "outputId": "c62acd81-e2e2-4a5e-c486-49674c3b56a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted text has been saved to ./output-信號與人生.txt.\n",
            "\n",
            "\n",
            "Review the results of splitting the long text into several short texts.\n",
            "\n",
            "\n",
            "========== The 1-st segment of the split (505 words) ==========\n",
            "\n",
            "\n",
            "每次說這個學問是做出來的 什麼意思? 要做才會獲得學問 你如果每天光是坐在那裡聽 學問很可能是左耳進右耳出的 你光是坐在那兒讀\n",
            "\n",
            "學問可能從眼睛進入腦海之後就忘掉了 如何能夠學問在腦海裡面 真的變成你自己學問 就是要做 可能有很多同學有這個經驗 你如果去修某一門課 或者做某一個實驗\n",
            "\n",
            "在期末就是要教一個final project 那個final project就是要你把 學到的很多東西 最後整合在你的final project裡面\n",
            "\n",
            "最後做出來的時候 就是把它們都整合了 當你學期結束 真的把final project做完的時候 你會忽然發現 我真的學到很多東西 那就是做出來的學問\n",
            "\n",
            "也許可以舉另外一個例子 就是你如果學了某一些很複雜的演算法 或者什麼 好像覺得那些不見得在你的腦海裡 可是後來老師出了個習題 那個習題教你寫一個很大的程式\n",
            "\n",
            "要把所有東西都包進去 當你把這個程式寫完的時候你會發現 你忽然把演算法裡所有東西都弄通了 那就是學問是做出來的 所以我們永遠要記得 盡量多動手多做\n",
            "\n",
            "在動手跟做的過程之中 學問纔可以變成是自己的 同樣的情形就是說 很多時候這樣動手或者做的表現或者成績 沒有一個成績單上的數字\n",
            "\n",
            "\n",
            "========== The 2-nd segment of the split (506 words) ==========\n",
            "\n",
            "\n",
            "使得很多人覺得那不重要 很多人甚至覺得這門課要做final project 我就不修了太累了 或者說那門課需要怎麼樣怎麼樣太累 我就不要做了\n",
            "\n",
            "而不知道其實那個纔是讓你做的機會 然後可以學到最多 也就是說雖然很可能那麼辛苦的做很多事 沒有讓你獲得什麼具體成績 對你的overfitting可能沒有幫助\n",
            "\n",
            "可是對你的全面學習是很有幫助 是該學的 那不要漏掉這些事 那這是我所說的 那這個課業內可以做的這些事 那剛才我們講到思考的時候 我覺得我漏掉一點\n",
            "\n",
            "你如果修我的信號課你可能會發現 我上課沒講到一個數學式子的時候 我通常都不推他的 我是在解釋那個數學式子在說什麼話 同樣的呢 沒講到一個什麼什麼事情的時候\n",
            "\n",
            "我通常就在解釋他在說什麼話 也就是說 我在講的就是我讀到特本那裡的時候 我心裡怎麼想的 也就是我在告訴同學如何這個讀書的時候 如何一面讀一面練習思考\n",
            "\n",
            "那這個纔是最重要的一件事 如何培養自己思考的能力 跟培養思考的習慣 我覺得最好的辦法就是讀書的時候 凡是讀到一個數學式子都去想一想 那個數學式子到底在說什麼\n",
            "\n",
            "凡是讀到特本上講什麼就去想一想 那個到底在說什麼 你要真的瞭解他在說什麼的時候 你就用了很多思考的功夫\n",
            "\n",
            "\n",
            "========== The 3-rd segment of the split (504 words) ==========\n",
            "\n",
            "\n",
            "你就在練習自己思考的能力了 好 以上說的是課業內的部分 那當然除了課業內之外呢 還有一大堆是不在課業內的 那就是課業外的 課業外也有很多式的 那我們可以舉例來說\n",
            "\n",
            "課業外有什麼可以學習的 那我通常把學習定義成為 什麼是學習 學習就是一種增長 一種進步 然後獲得快樂 這就是學習 所以即使是課業外的任何事情\n",
            "\n",
            "只要你覺得是有增長的 是有進步的 讓你覺得快樂的 那應該就是值得學習的地方 那我們可以舉很多例子 譬如說很多同學喜歡打球 打球是不是學習 當然是\n",
            "\n",
            "在打球中間有沒有增長 當然是 在打球中間有沒有增長 當然有增長 打球不只是對健康有增長 而且可能對於譬如說手腦協調 譬如說團隊精神 譬如說個人之間的互動\n",
            "\n",
            "什麼可能都有幫助 所以打球當然是有增長的 那當然是很好的學習的機會 有人喜歡爬山 爬山是不是好的學習機會 當然是 這個我以前兩年前就講過很多 爬山可以學到很多的\n",
            "\n",
            "那爬山當然是一種學習 有人說我不喜歡爬山 我去旅行好不好 旅行當然好 旅行可以增長見識 可以擴增事業 可以增加很多很多 當然是有進步的 所以當然是很好的學習\n",
            "\n",
            "你凡是獲得快樂都是很好的事 那這些都值得下功夫去 把它看成是學習 都值得下功夫去做的\n",
            "\n",
            "\n",
            "========== The 4-th segment of the split (506 words) ==========\n",
            "\n",
            "\n",
            "我們再講另外一系列 譬如說 有人說談戀愛是不是學習 談戀愛除了你在談戀愛上 會有收穫以外 本身也是有收穫的 因為讓你體驗到人跟人之間 的各種感覺\n",
            "\n",
            "人跟人之間的各種期待等等 有沒有幫助 當然有幫助 對每一個人都是很好的學習 所以談戀愛當然是一件很好的事 有人會說那要靠緣分 沒有緣分沒有辦法 對不對 對\n",
            "\n",
            "但是你不是一定要談戀愛嗎 你可以交朋友 交朋友是不是學習 當然是 交朋友也一樣 讓我們學到很多人際的互動 學到很多人跟人之間的溝通 人跟人之間的期待\n",
            "\n",
            "人跟人之間的感覺 這都是交朋友之後學到的 對我們電機系的同學而言 你四周有一大羣好同學 都是很好的交朋友的對象 你下一番功夫交朋友好不好 好 當然是有幫助的\n",
            "\n",
            "另外當然我們可以舉很多 我們最現成的例子 譬如說我們的戲學會辦各種活動 那些活動有沒有幫助 當然有 我們舉例來講電業 你如果去參加某一個舞跳個舞\n",
            "\n",
            "或者參加某個劇演個劇 有沒有幫助 當然有幫助 你在這中間一定發現有所增長 有所進步 那是為什麼有那麼多同學要去參加 就是因為發現那個確實是有增長有進步 有的人說\n",
            "\n",
            "我不去跳那個舞 或者演那個劇 我做幕後的 譬如說是幕後的什麼規劃 或者說是什麼光舞的什麼軟體組\n",
            "\n",
            "\n",
            "========== The 5-th segment of the split (501 words) ==========\n",
            "\n",
            "\n",
            "還是什麼服裝道具組 一樣 那個都是可以有獲得很多的增長 很多進步的 當然都是很有用的 都是很好的學習 那當然也包括電業以外的戲學會 其他的各種活動都一樣\n",
            "\n",
            "也包括電機系以外的其他的校內 或者校外的各種活動幾乎都一樣 都可以讓人有所增長有所進步 都是很好的學習的機會 都是很好的學習 同樣的問題是這些東西都沒有考試\n",
            "\n",
            "沒有成績 不能顯示在成績單上 因此對有一些同學會認為那個浪費時間 我不需要花時間去做那個 因為不影響我的overfitting的目標 裡面沒有這個嘛\n",
            "\n",
            "具體成績沒有這些嘛 那不要這樣想 因為那些都非常的重要 都對你發展非常的重要 那我們說電機工程 今天的電機工程 很少什麼事情自己一個人可以做成功的\n",
            "\n",
            "你必須跟很多人一起 纔可能做成功一個非常重要的 有意義的工作 那當你跟一羣人在一起做的時候 你必須學會如何進入一個團隊 從邊緣開始慢慢進入核心\n",
            "\n",
            "從底層開始慢慢變成leader 然後如何可以推動你想做的事 如何變成可以做到你想做的事等等 這些都是很重要的 那我們通常稱這些東西 是所謂的soft\n",
            "\n",
            "skills 也就是軟實力 所謂軟實力就是硬實力以外的軟實力 硬實力是說你電子學的功力 數學的功力\n",
            "\n",
            "\n",
            "========== The 6-th segment of the split (504 words) ==========\n",
            "\n",
            "\n",
            "這個城市能力這種是硬實力 軟實力我們主要就是講各種人際之間的 在人跟人之間的各種能力 包括溝通能力協調能力交朋友的能力 說服人的能力團隊精神領導能力等等\n",
            "\n",
            "那些就是所謂的soft skills 重要不重要重要 你看到任何一個成功的電機工程師 他都有一堆這種 這個纔是他成功的一個非常重要的關鍵 這種東西怎麼來\n",
            "\n",
            "我們剛才講的各種課業外的 各種學習增長的機會 都可以幫助一個人塑造他的soft skills 是有少數人的這些soft skills是天生的 他天生就厲害\n",
            "\n",
            "有沒有 有 但這種人畢竟沒那麼多 對很多人而言 他的soft skills是自己努力慢慢培養起來的 我剛才一開始前面講的那一段 我說我在進臺大電機系以前\n",
            "\n",
            "我幾乎不會交朋友 我不太會說話 我在讀大學的四年裡面改變我自己 讓我變成有很多這方面的能力的人 其實最重要就是我的很多soft skills 都是我自己培養\n",
            "\n",
            "在讀臺大電機系的四年裡面 獲得的非常多這方面的收穫的 那是為什麼我每次都要強調 這個東西有多麼重要 我之前曾經在幾年前的這個 信號與人生裡面有說到這一件事\n",
            "\n",
            "我現在不要重複 但是我簡單的summarize 我說我們電機系的電機工程師的\n",
            "\n",
            "\n",
            "========== The 7-th segment of the split (502 words) ==========\n",
            "\n",
            "\n",
            "一生career的發展 黃金實在是在什麼時候 我認為是在35歲到55歲 這20年是我們的黃金時代 在這以前當然更好 只是說可能各方面尚未具備 還沒有完全訓練的好\n",
            "\n",
            "在這以後是最好的 這以後年紀大了難免有一些要打個折扣等等 就這裡面我們看到 我們的電機系的畢業的同學 過去有幾千人畢業我都看到 我覺得有的人的發展是像這樣\n",
            "\n",
            "有一定的斜率 但到某一個階段它會慢慢saturate 有的人也許開始向上比較晚 但它斜率比較高 它最後會saturate在比較高的地方 也有的人也許開始的比較快\n",
            "\n",
            "但是後來會overshoot之後 會開始收斂在比較低的地方等等 每一個人都不一樣 但是當然也有一種人 你會看到他一直向上走 完全沒有saturate\n",
            "\n",
            "這些人這些差別在哪裡 這些東西差別在哪裡 我以前已經說過這件事 我不要多重複 我說最主要因素有四個 實力、努力、大智 跟self skill這四件事情\n",
            "\n",
            "我認為真正影響這個的 不是因為電子學考得好不好 不是因為信號與系統念得好不好 也就是我剛才講 你把每一門必修課 當成是單一跑道 跑到第一名並不表示怎樣\n",
            "\n",
            "我們最後不看那個的 最後看的是這個 這個是怎麼樣影響 我認為是這四件事\n",
            "\n",
            "\n",
            "========== The 8-th segment of the split (512 words) ==========\n",
            "\n",
            "\n",
            "就是實力、努力、大智跟self skills 這四件事裡面 我們現在可以summarize 我剛才講的 什麼是實力 實力就是所有的這些\n",
            "\n",
            "我們電機工程的專業領域裡面 各種東西的實力 實力怎麼厲害法 就是我剛才講的 你如果都是在做全面的學習的話 你就會學到各種該學到的 最後你的實力就是很強的\n",
            "\n",
            "所以實力最主要就是不要overfitting 要盡量都做 學到該學的全面的學習 努力是沒有疑問 每一個人都瞭解 確實我們可以看到 一個人在未來的幾十年裡面\n",
            "\n",
            "有的人他一直努力 有的人慢慢不太努力等等 這個是有明顯差別的 那self skills我剛才已經講了 就是很多我們平常沒有算成績 覺得大家不重視的事情\n",
            "\n",
            "其實它常常是很重要的 你如果好好的 多在各種課業外的事情上 增長進步的話 你這些東西會很強 你會很厲害的 當然對少數人而言 他天生就有 他可能不需要\n",
            "\n",
            "這是每一個人不一樣的 那這三個我都提過了 那麼大致我還沒有提 其實大致沒有什麼要特別說的 那應該就是我剛才前面有講過 就是每一個人可以有你自己的長程目標\n",
            "\n",
            "那有的人本來就有了 有的人也許我平常沒有想過 那你可以在適當時機開始想 我有沒有想要做什麼事情 哪些事情可能是我的長程目標\n",
            "\n",
            "\n",
            "========== The 9-th segment of the split (169 words) ==========\n",
            "\n",
            "\n",
            "我希望最後讓我花個5年10年 15年或者更長 我把我的很多的努力 都來把某一些事情做得非常漂亮 那是我很想做的事 那就是長程目標\n",
            "\n",
            "如果我覺得做那些事情會讓我非常的 覺得有意義 願意花功夫下去做的 那就是我的長程目標 那有的人如果可以想出這個來的話 那就是他的大致 那越是有這種大致的人\n",
            "\n",
            "也比較容易向上衝 那我感覺起來真正影響的就是這四件事\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extracts the text from an SRT file and saves it to a new text file\n",
        "pure_text = extract_and_save_text(srt_filename=output_subtitle_path, output_filename=output_raw_text_path)\n",
        "\n",
        "# Split a long document into smaller chunks of a specified length\n",
        "chunks = chunk_text(text=pure_text, max_length=512)\n",
        "\n",
        "# You can see the number of words and contents in each paragraph.\n",
        "print(\"Review the results of splitting the long text into several short texts.\\n\")\n",
        "for index, chunk in enumerate(chunks):\n",
        "    if index == 0:\n",
        "        print(f\"\\n========== The {index + 1}-st segment of the split ({len(chunk)} words) ==========\\n\\n\")\n",
        "        for text in textwrap.wrap(chunk, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "    elif index == 1:\n",
        "        print(f\"\\n========== The {index + 1}-nd segment of the split ({len(chunk)} words) ==========\\n\\n\")\n",
        "        for text in textwrap.wrap(chunk, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "    elif index == 2:\n",
        "        print(f\"\\n========== The {index + 1}-rd segment of the split ({len(chunk)} words) ==========\\n\\n\")\n",
        "        for text in textwrap.wrap(chunk, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "    else:\n",
        "        print(f\"\\n========== The {index + 1}-th segment of the split ({len(chunk)} words) ==========\\n\\n\")\n",
        "        for text in textwrap.wrap(chunk, 80):\n",
        "            print(f\"{text}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuvx30fkW4kU"
      },
      "source": [
        "# Part4 - Summarization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mr9Kz634zT2"
      },
      "source": [
        "## **You only need to choose one of the following parts.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCPYjOAyXWaE"
      },
      "source": [
        "## **If you want to use ChatGPT, begin with this part.**\n",
        "##### (1) You can refer to https://shorturl.at/X0NDY (Page 44) for obtaining ChatGPT API key.\n",
        "##### (2) You can refer to https://platform.openai.com/docs/models/overview for more details about models you can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCara20SW8AN"
      },
      "outputs": [],
      "source": [
        "def summarization(client, summarization_prompt, model_name=\"gpt-3.5-turbo\", temperature=0.0, top_p=1.0, max_tokens=512):\n",
        "    \"\"\"\n",
        "    (1) Objective:\n",
        "        - Use the OpenAI Chat API to summarize a given text.\n",
        "\n",
        "    (2) Arguments:\n",
        "        - client: OpenAI Chat API client.\n",
        "        - summarization_prompt: The summarization prompt including the text which need to be summarized.\n",
        "        - model_name: The model name, default is \"gpt-3.5-turbo\". You can refer to \"https://platform.openai.com/docs/models/overview\" for more details.\n",
        "        - temperature: Controls randomness in the response. Lower values make responses more deterministic, default is 0.0.\n",
        "        - top_p: Controls diversity via nucleus sampling. Higher values lead to more diverse responses, default is 1.0.\n",
        "        - max_tokens: The maximum number of tokens to generate in the completion, default is 512.\n",
        "\n",
        "    (3) Return:\n",
        "        - The summarized text.\n",
        "\n",
        "    (4) Example:\n",
        "        - If the text is \"ABC\" and the summarization prompt is \"DEF\", system_prompt is \"GHI\", model_name is \"gpt-3.5-turbo\",\n",
        "          temperature is 0.0, top_p is 1.0, and max_tokens is 512, then you can call the function like this:\n",
        "\n",
        "              summarization(client=client, text=\"ABC\", summarization_prompt=\"DEF\", system_prompt=\"GHI\", model_name=\"gpt-3.5-turbo\", temperature=0.0, top_p=1.0, max_tokens=512)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # The user prompt is a concatenation of the summarization_prompt and text.\n",
        "    user_prompt = summarization_prompt\n",
        "\n",
        "    while True:\n",
        "\n",
        "        try:\n",
        "            # Use the OpenAI Chat API to summarize the text.\n",
        "            chat_completion = client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": user_prompt,\n",
        "                    }\n",
        "                ],\n",
        "                    model=model_name,\n",
        "                    temperature=temperature,\n",
        "                    top_p=top_p,\n",
        "                    max_tokens=max_tokens\n",
        "            )\n",
        "\n",
        "            break\n",
        "\n",
        "        except:\n",
        "            # If the API call fails, wait for 1 second and try again.\n",
        "            print(\"The API call fails, wait for 1 second and try again.\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p3VZeUfBYcih"
      },
      "outputs": [],
      "source": [
        "# @title Parameter Setting of ChatGPT { run: \"auto\" }\n",
        "''' ===== In this block, you can modify your desired parameters and set your OpenAI API key ===== '''\n",
        "\n",
        "# Your OpenAI API key.\n",
        "# @markdown **openai_api_key**: Your OpenAI API key.\n",
        "openai_api_key = \"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\" # @param {type:\"string\"}\n",
        "\n",
        "# The model name, default is \"gpt-3.5-turbo\". You can refer to \"https://platform.openai.com/docs/models/overview\" for more details.\n",
        "# @markdown **model_name**: The model name, default is \"gpt-3.5-turbo\". You can refer to \"https://platform.openai.com/docs/models/overview\" for more details.\n",
        "model_name = \"gpt-3.5-turbo\" # @param {type: \"string\"}\n",
        "\n",
        "# Controls randomness in the response. Lower values make responses more deterministic.\n",
        "# @markdown **temperature**: Controls randomness in the response. Lower values make responses more deterministic.\n",
        "temperature = 0 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "# Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "# @markdown **top_p**: Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "top_p = 0 # @param {type:\"slider\", min:0, max:1, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysnuD_eIeWjY"
      },
      "outputs": [],
      "source": [
        "# Construct openai client.\n",
        "client = OpenAI(api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwDxai-YY4Hl"
      },
      "source": [
        "The code block below takes about **30** seconds to run when using the **gpt-3.5-turbo** model, but the actual time may vary depending on the condition of Colab and the status of the OpenAI API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvCBfcW7Qd-e"
      },
      "source": [
        "### We offer the following two methods for summarization.\n",
        "Reference: https://reurl.cc/VzagLA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9QC8lG_QRZL"
      },
      "source": [
        "#### **If you want to use the method of Multi-Stage Summarization, begin with this part.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUma_oXAQtmg"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of ChatGPT Multi-Stage Summarization: Paragraph { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# The maximum number of tokens to generate in the completion.\n",
        "# @markdown **max_tokens**: The maximum number of tokens to generate in the completion.\n",
        "max_tokens = 350 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown #### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"用 300 個字內寫出這段文字的摘要，其中包括要點和所有重要細節：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQtk04XATy1j"
      },
      "source": [
        "##### Step1: Split the long text into multiple smaller pieces and obtain summaries for each smaller text piece separately"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUTFgIGl1IRp"
      },
      "source": [
        "The code block below takes about **80** seconds to run when using the (1) **gpt-3.5-turbo** model, (2) length of chunks is 512 and (3) maximum number of tokens is 250, but the actual time may vary depending on the condition of Colab and the status of the OpenAI API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv-Ko3UZYjpg",
        "outputId": "c9513947-a9c4-4915-c6e8-8fe6f3fb221d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------Summary of Segment 1----------------------------\n",
            "\n",
            "學問是需要透過實際做來獲得的。單純地聽或閱讀可能無法真正吸收知識。透過完成作業或專案，將所學知識整合並應用，才能真正理解和掌握。舉例來說，完成一個專案或寫一個程\n",
            "\n",
            "式可以幫助我們將學到的知識融會貫通。因此，我們應該多動手多做，讓學問真正成為自己的。成績單上的分數並不一定能完全反映我們對知識的掌握程度。\n",
            "\n",
            "Length of summary for segment 1: 149\n",
            "Time taken to generate summary for segment 1: 4.82 sec.\n",
            "\n",
            "----------------------------Summary of Segment 2----------------------------\n",
            "\n",
            "許多人認為某門課不重要，甚至選擇不修或不做 final project，因為覺得太累或不必要。然而，這些看似無用的事實際上是學習的機會，能夠讓你全面成長。即使做\n",
            "\n",
            "了很多辛苦的事情可能沒有具體成果，但對於全面學習和思考能力的培養卻是很有幫助的。重要的是要不漏掉這些機會，並在讀書時思考數學式子和概念，培養自己的思考能力和習慣\n",
            "\n",
            "。這樣才能真正理解所學知識，並提升自己的思考能力。\n",
            "\n",
            "Length of summary for segment 2: 185\n",
            "Time taken to generate summary for segment 2: 5.35 sec.\n",
            "\n",
            "----------------------------Summary of Segment 3----------------------------\n",
            "\n",
            "學習不僅僅存在於課業之中，課業外也有很多可以學習的地方。學習是一種增長、進步和獲得快樂的過程。例如，打球可以提升健康、手腦協調、團隊精神和人際互動能力；爬山可以\n",
            "\n",
            "增加見識和學習到很多東西；旅行也可以擴展視野和增加經驗。無論是什麼活動，只要讓你感到快樂並有所增長和進步，都值得花時間和精力去學習。所以，把這些課外活動看成是學\n",
            "\n",
            "習的機會，都是值得努力去做的事情。\n",
            "\n",
            "Length of summary for segment 3: 177\n",
            "Time taken to generate summary for segment 3: 6.07 sec.\n",
            "\n",
            "----------------------------Summary of Segment 4----------------------------\n",
            "\n",
            "談戀愛和交朋友都是學習人際互動和溝通的好機會，即使沒有緣分也可以透過交朋友來學習。在大學裡，有很多機會參加各種活動，例如戲劇社或舞蹈社，這些活動可以幫助我們成長\n",
            "\n",
            "和進步。即使不是表演者，幕後工作也同樣重要，例如規劃或軟體組。在電機系裡，有很多優秀的同學可以成為好朋友，所以努力交朋友是有幫助的。透過參加各種活動，我們可以學\n",
            "\n",
            "到很多人與人之間的互動和溝通技巧，這對我們的成長和發展都是很重要的。\n",
            "\n",
            "Length of summary for segment 4: 194\n",
            "Time taken to generate summary for segment 4: 6.48 sec.\n",
            "\n",
            "----------------------------Summary of Segment 5----------------------------\n",
            "\n",
            "這段文字談論到不僅在電機工程領域，其他活動也能帶來成長和進步，包括戲劇學會和校內外的各種活動。儘管這些活動沒有考試或成績，但它們對個人發展非常重要。在今天的電機\n",
            "\n",
            "工程中，成功很少是一個人完成的，需要與他人合作。學習如何進入團隊、成為領導者並推動想做的事情是必要的。這些被稱為軟實力，是除了硬實力外的重要技能。\n",
            "\n",
            "Length of summary for segment 5: 153\n",
            "Time taken to generate summary for segment 5: 5.43 sec.\n",
            "\n",
            "----------------------------Summary of Segment 6----------------------------\n",
            "\n",
            "成功與否不僅取決於硬實力，更重要的是軟實力，包括人際交往能力、溝通能力、領導能力等。這些soft skills對於成功至關重要，並且可以透過課外活動和學習機會來\n",
            "\n",
            "培養。雖然有些人天生具備這些能力，但大多數人需要透過努力培養。作者分享自己在大學期間透過努力培養soft\n",
            "\n",
            "skills的經驗，強調這些能力對於電機工程師的成功至關重要。\n",
            "\n",
            "Length of summary for segment 6: 164\n",
            "Time taken to generate summary for segment 6: 4.39 sec.\n",
            "\n",
            "----------------------------Summary of Segment 7----------------------------\n",
            "\n",
            "在35歲到55歲這20年間被視為人生的黃金時期，這段時間是最好的發展時期。在這個時期之前，可能各方面尚未具備，還沒有完全訓練好；而之後，年紀大了可能會有一些限制\n",
            "\n",
            "。在電機系的畢業同學中，有些人的發展呈現斜率逐漸趨緩，有些人開始晚但斜率較高，也有些人起步快但後來趨於平緩。每個人的情況不同，但實力、努力、大智和self\n",
            "\n",
            "skill是影響發展的主要因素，而不僅僅是學業成績。最終，重要的是這四個因素如何影響個人的發展。\n",
            "\n",
            "Length of summary for segment 7: 206\n",
            "Time taken to generate summary for segment 7: 5.85 sec.\n",
            "\n",
            "----------------------------Summary of Segment 8----------------------------\n",
            "\n",
            "這段文字主要談到了實力、努力、大智和self skills 四個重要的要素。實力是指在電機工程領域中各種技能和知識的總和，要盡量做全面的學習以避免overfit\n",
            "\n",
            "ting。努力是每個人都應該具備的品質，對未來的發展有著重要影響。self skills\n",
            "\n",
            "指的是平常被忽視但卻很重要的技能，通過在課業外的事情上增長進步可以讓自己變得更強大。此外，每個人都應該有自己的長程目標，這將有助於指導未來的努力和發展方向。\n",
            "\n",
            "Length of summary for segment 8: 203\n",
            "Time taken to generate summary for segment 8: 5.43 sec.\n",
            "\n",
            "----------------------------Summary of Segment 9----------------------------\n",
            "\n",
            "我希望在未來的5年、10年、15年甚至更長的時間裡，專注於努力實現我想要做的事情，這是我的長程目標。如果我認為這些事情對我來說非常有意義，我願意花時間和精力去實\n",
            "\n",
            "現。擁有這種長程目標的人更容易朝著成功的方向前進。對我來說，這四件事情是真正影響我未來的關鍵。\n",
            "\n",
            "Length of summary for segment 9: 127\n",
            "Time taken to generate summary for segment 9: 4.49 sec.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    # Record the start time.\n",
        "    start = time.time()\n",
        "\n",
        "    # Construct summarization prompt.\n",
        "    summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "    # We summarize each section that has been split up separately.\n",
        "    response = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "    # Calculate the execution time and round it to 2 decimal places.\n",
        "    cost_time = round(time.time() - start, 2)\n",
        "\n",
        "    # Print the summary and its length.\n",
        "    print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "    for text in textwrap.wrap(response, 80):\n",
        "        print(f\"{text}\\n\")\n",
        "    print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "    print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Record the result.\n",
        "    paragraph_summarizations.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6QXhSK_eACs",
        "outputId": "9ff2bf63-36c3-47f9-d301-9eef0d4da28d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of segment 1: 學問是需要透過實際做來獲得的。單純地聽或閱讀可能無法真正吸收知識。透過完成作業或專案，將所學知識整合並應用，才能真正理解和掌握。舉例來說，完成一個專案或寫一個程式可以幫助我們將學到的知識融會貫通。因此，我們應該多動手多做，讓學問真正成為自己的。成績單上的分數並不一定能完全反映我們對知識的掌握程度。\n",
            "Summary of segment 2: 許多人認為某門課不重要，甚至選擇不修或不做 final project，因為覺得太累或不必要。然而，這些看似無用的事實際上是學習的機會，能夠讓你全面成長。即使做了很多辛苦的事情可能沒有具體成果，但對於全面學習和思考能力的培養卻是很有幫助的。重要的是要不漏掉這些機會，並在讀書時思考數學式子和概念，培養自己的思考能力和習慣。這樣才能真正理解所學知識，並提升自己的思考能力。\n",
            "Summary of segment 3: 學習不僅僅存在於課業之中，課業外也有很多可以學習的地方。學習是一種增長、進步和獲得快樂的過程。例如，打球可以提升健康、手腦協調、團隊精神和人際互動能力；爬山可以增加見識和學習到很多東西；旅行也可以擴展視野和增加經驗。無論是什麼活動，只要讓你感到快樂並有所增長和進步，都值得花時間和精力去學習。所以，把這些課外活動看成是學習的機會，都是值得努力去做的事情。\n",
            "Summary of segment 4: 談戀愛和交朋友都是學習人際互動和溝通的好機會，即使沒有緣分也可以透過交朋友來學習。在大學裡，有很多機會參加各種活動，例如戲劇社或舞蹈社，這些活動可以幫助我們成長和進步。即使不是表演者，幕後工作也同樣重要，例如規劃或軟體組。在電機系裡，有很多優秀的同學可以成為好朋友，所以努力交朋友是有幫助的。透過參加各種活動，我們可以學到很多人與人之間的互動和溝通技巧，這對我們的成長和發展都是很重要的。\n",
            "Summary of segment 5: 這段文字談論到不僅在電機工程領域，其他活動也能帶來成長和進步，包括戲劇學會和校內外的各種活動。儘管這些活動沒有考試或成績，但它們對個人發展非常重要。在今天的電機工程中，成功很少是一個人完成的，需要與他人合作。學習如何進入團隊、成為領導者並推動想做的事情是必要的。這些被稱為軟實力，是除了硬實力外的重要技能。\n",
            "Summary of segment 6: 成功與否不僅取決於硬實力，更重要的是軟實力，包括人際交往能力、溝通能力、領導能力等。這些soft skills對於成功至關重要，並且可以透過課外活動和學習機會來培養。雖然有些人天生具備這些能力，但大多數人需要透過努力培養。作者分享自己在大學期間透過努力培養soft skills的經驗，強調這些能力對於電機工程師的成功至關重要。\n",
            "Summary of segment 7: 在35歲到55歲這20年間被視為人生的黃金時期，這段時間是最好的發展時期。在這個時期之前，可能各方面尚未具備，還沒有完全訓練好；而之後，年紀大了可能會有一些限制。在電機系的畢業同學中，有些人的發展呈現斜率逐漸趨緩，有些人開始晚但斜率較高，也有些人起步快但後來趨於平緩。每個人的情況不同，但實力、努力、大智和self skill是影響發展的主要因素，而不僅僅是學業成績。最終，重要的是這四個因素如何影響個人的發展。\n",
            "Summary of segment 8: 這段文字主要談到了實力、努力、大智和self skills 四個重要的要素。實力是指在電機工程領域中各種技能和知識的總和，要盡量做全面的學習以避免overfitting。努力是每個人都應該具備的品質，對未來的發展有著重要影響。self skills 指的是平常被忽視但卻很重要的技能，通過在課業外的事情上增長進步可以讓自己變得更強大。此外，每個人都應該有自己的長程目標，這將有助於指導未來的努力和發展方向。\n",
            "Summary of segment 9: 我希望在未來的5年、10年、15年甚至更長的時間裡，專注於努力實現我想要做的事情，這是我的長程目標。如果我認為這些事情對我來說非常有意義，我願意花時間和精力去實現。擁有這種長程目標的人更容易朝著成功的方向前進。對我來說，這四件事情是真正影響我未來的關鍵。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# First, we collect all the summarizations obtained before and print them.\n",
        "\n",
        "collected_summarization = \"\"\n",
        "for index, paragraph_summarization in enumerate(paragraph_summarizations):\n",
        "    collected_summarization += f\"Summary of segment {index + 1}: {paragraph_summarization}\\n\"\n",
        "\n",
        "print(collected_summarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itdqp3H5T2T7"
      },
      "source": [
        "##### Step2: After obtaining summaries for each smaller text piece separately, process these summaries to generate the final summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0ghZaKfVEyN"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of ChatGPT Multi-Stage Summarization: Total { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"在 500 字以內寫出以下文字的簡潔摘要：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka0JcOvYVIWu"
      },
      "source": [
        "The code block below takes about **10** seconds to run when using the (1) **gpt-3.5-turbo** model and (2) maximum number of tokens is 500, but the actual time may vary depending on the condition of Colab and the status of the OpenAI API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zHPMRDWeCuq"
      },
      "outputs": [],
      "source": [
        "# Finally, we compile a final summary from the summaries of each section.\n",
        "\n",
        "# Record the start time.\n",
        "start = time.time()\n",
        "\n",
        "# Run final summarization.\n",
        "summarization_prompt = summarization_prompt_template.replace(\"<text>\", collected_summarization)\n",
        "final_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "# Calculate the execution time and round it to 2 decimal places.\n",
        "cost_time = round(time.time() - start, 2)\n",
        "\n",
        "# Print the summary and its length.\n",
        "print(f\"----------------------------Final Summary----------------------------\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 80):\n",
        "        print(f\"{text}\")\n",
        "print(f\"\\nLength of final summary: {len(final_summarization)}\")\n",
        "print(f\"Time taken to generate the final summary: {cost_time} sec.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qi7eERB8eGdK"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-chatgpt-multi-stage.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    final_summarization = cc.convert(final_summarization)\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(final_summarization)\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(final_summarization)} words) =====\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 64):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRzf_0cTV6TS"
      },
      "source": [
        "#### **If you want to use the method of Refinement, begin with this part.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k79C13kWW_Ye"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of ChatGPT Refinement { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template** and **summarization_prompt_refine_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "\n",
        "# Initial prompt.\n",
        "# @markdown **summarization_prompt_template**: Initial prompt.\n",
        "summarization_prompt_template = \"請在 300 字以內，提供以下文字的簡潔摘要:<text>\" # @param {type:\"string\"}\n",
        "\n",
        "# Refinement prompt.\n",
        "# @markdown **summarization_prompt_refinement_template**: Refinement prompt.\n",
        "summarization_prompt_refinement_template = \"請在 500 字以內，結合原先的摘要和新的內容，提供簡潔的摘要:<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEtfC9WeZkNH"
      },
      "source": [
        "The code block below takes about **200** seconds to run when using the (1) **gpt-3.5-turbo** model and (2) maximum number of tokens is 500, but the actual time may vary depending on the condition of Colab and the status of the OpenAI API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rugUlJ6HeZPF"
      },
      "source": [
        "Pipeline of the method of Refinement.\n",
        "\n",
        "Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "\n",
        "Step2: For each following document, the previous output is fed in along with the new document.\n",
        "\n",
        "Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "\n",
        "Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aFmk1ATAOdd"
      },
      "outputs": [],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    if index == 0:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Construct summarization prompt.\n",
        "        summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "        # Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "        first_paragraph_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(first_paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # Print the summary and its length.\n",
        "        print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "        for text in textwrap.wrap(response, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "        print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Step2: For each following document, the previous output is fed in along with the new document.\n",
        "        chunk_text = f\"\"\"前 {index} 段的摘要: {paragraph_summarizations[-1]}\\n第 {index + 1} 段的內容: {chunk}\"\"\"\n",
        "\n",
        "        # Construct refinement prompt for summarization.\n",
        "        summarization_prompt = summarization_prompt_refinement_template.replace(\"<text>\", chunk_text)\n",
        "\n",
        "        # Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "        paragraph_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # print results.\n",
        "        print(f\"----------------------------Summary of the First {index + 1} Segments----------------------------\\n\")\n",
        "        for text in textwrap.wrap(paragraph_summarization, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for the first {index + 1} segments: {len(paragraph_summarization)}\")\n",
        "        print(f\"Time taken to generate summary for the first {index + 1} segments: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaXWOLIOa4dM"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-chatgpt-refinement.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    paragraph_summarizations[-1] = cc.convert(paragraph_summarizations[-1])\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(paragraph_summarizations[-1])\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(paragraph_summarizations[-1])} words) =====\\n\")\n",
        "for text in textwrap.wrap(paragraph_summarizations[-1], 80):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCM4kPuBXh7R"
      },
      "source": [
        "## **If you want to use Gemini, begin with this part.**\n",
        "##### (1) You can refer to https://shorturl.at/X0NDY (Page 35) for obtaining Gemini API key.\n",
        "##### (2) You can refer to https://ai.google.dev/models/gemini for more details about which models you can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anuFrhHNkMgY"
      },
      "outputs": [],
      "source": [
        "def summarization(summarization_prompt, model_name=\"gemini-pro\", temperature=0.0, top_p=1.0, max_tokens=512):\n",
        "    \"\"\"\n",
        "    (1) Objective:\n",
        "        - Use the OpenAI Chat API to summarize a given text.\n",
        "\n",
        "    (2) Arguments:\n",
        "        - summarization_prompt: The summarization prompt.\n",
        "        - model_name: The model name, default is \"gemini-pro\". You can refer to \"https://ai.google.dev/models/gemini\" for more details.\n",
        "        - temperature: Controls randomness in the response. Lower values make responses more deterministic, default is 0.0.\n",
        "        - top_p: Controls diversity via nucleus sampling. Higher values lead to more diverse responses, default is 1.0.\n",
        "        - max_tokens: The maximum number of tokens to generate in the completion, default is 512.\n",
        "\n",
        "    (3) Return:\n",
        "        - The summarized text.\n",
        "\n",
        "    (4) Example:\n",
        "        - If the text is \"ABC\" and the summarization prompt is \"DEF\", model_name is \"gemini-pro\",\n",
        "          temperature is 0.0, top_p is 1.0, and max_tokens is 512, then you can call the function like this:\n",
        "\n",
        "              summarization(text=\"ABC\", summarization_prompt=\"DEF\", model_name=\"gemini-pro\", temperature=0.0, top_p=1.0, max_tokens=512)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # The user prompt is a concatenation of the summarization_prompt and text.\n",
        "    user_prompt = summarization_prompt\n",
        "\n",
        "    # Load the generative model.\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "\n",
        "    # Set the generation configuration.\n",
        "    generation_config = genai.GenerationConfig(temperature=temperature, top_p=top_p, max_output_tokens=max_tokens)\n",
        "\n",
        "    while True:\n",
        "\n",
        "        try:\n",
        "            # Use the OpenAI Chat API to summarize the text.\n",
        "            response = model.generate_content(contents=user_prompt, generation_config=generation_config)\n",
        "            break\n",
        "\n",
        "        except:\n",
        "            # If the API call fails, wait for 1 second and try again.\n",
        "            print(\"The API call fails, wait for 1 second and try again.\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plyvWCvXllz3"
      },
      "outputs": [],
      "source": [
        "# @title Parameter Setting of Gemini { run: \"auto\" }\n",
        "''' In this block, you can modify your desired parameters and set your api key. '''\n",
        "\n",
        "# Your google api key.\n",
        "# @markdown **google_api_key**: Your google api key.\n",
        "google_api_key = \"AIzaSyBC244MBtN2wL41pC695ENK8UBV9VezKFg\" # @param {type:\"string\"}\n",
        "\n",
        "# The model name. You can refer to \"https://ai.google.dev/models/gemini\" for more details.\n",
        "# @markdown **model_name**: The model name. You can refer to \"https://ai.google.dev/models/gemini\" for more details.\n",
        "model_name = \"gemini-1.5-pro\" # @param {type:\"string\"}\n",
        "\n",
        "# Controls randomness in the response. Lower values make responses more deterministic\n",
        "# @markdown **temperature**: Controls randomness in the response. Lower values make responses more deterministic.\n",
        "temperature = 0.0 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "# Controls diversity via nucleus sampling. Higher values lead to more diverse responses\n",
        "# @markdown **top_p**: Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "top_p = 1.0 # @param {type:\"slider\", min:0, max:1, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eed0NjqJtGfM"
      },
      "outputs": [],
      "source": [
        "# Set Google API key.\n",
        "genai.configure(api_key=google_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csw7hxrHsJym"
      },
      "source": [
        "### We offer the following two methods for summarization.\n",
        "Reference: https://reurl.cc/VzagLA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGHFGCyasp9h"
      },
      "source": [
        "#### **If you want to use the method of Multi-Stage Summarization, begin with this part.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TsX6dBgs1iw"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Gemini Multi-Stage Summarization: Paragraph { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# The maximum number of tokens to generate in the completion.\n",
        "# @markdown **max_tokens**: The maximum number of tokens to generate in the completion.\n",
        "max_tokens = 350 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown #### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"用 300 個字內寫出這段文字的摘要，其中包括要點和所有重要細節，我將給你一億元：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkQdOOixuJU9"
      },
      "source": [
        "##### Step1: Split the long text into multiple smaller pieces and obtain summaries for each smaller text piece separately\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olrUkpe615-E"
      },
      "source": [
        "The code block below takes about **40** seconds to run when using the (1) **gemini-pro** model, (2) length of chunks is 512 and (3) maximum number of tokens is 350, but the actual time may vary depending on the condition of Colab and the status of the Google API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5KOp_d6XloCn",
        "outputId": "c6655744-0349-4597-f623-858e79eebb3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------Summary of Segment 1----------------------------\n",
            "\n",
            "這段文字主要闡述了一個觀點：學問是做出來的，而非僅僅聽講或閱讀就能獲得。作者用兩個例子說明：  1. **完成期末專案：**\n",
            "\n",
            "將課堂所學知識整合應用，最終做出的成果能讓你真正掌握知識。 2. **編寫複雜程式：** 通過實踐將演算法等抽象知識應用到具體程式中，才能真正理解和掌握。\n",
            "\n",
            "作者強調，動手實踐是將知識內化的關鍵，儘管這個過程可能沒有成績單上的數字來衡量，但它能讓學問真正成為自己的。\n",
            "\n",
            "Length of summary for segment 1: 198\n",
            "Time taken to generate summary for segment 1: 7.16 sec.\n",
            "\n",
            "----------------------------Summary of Segment 2----------------------------\n",
            "\n",
            "這段文字的核心觀點是：**真正的學習機會往往藏在看似辛苦、沒有直接回報的事情中，例如課程專案和深入思考。**\n",
            "\n",
            "很多人因為怕累而逃避這些挑戰，但其實這些挑戰才能帶來最大的學習效益。\n",
            "\n",
            "作者以自身教學經驗為例，強調理解知識背後的意義比死記硬背公式更重要。他鼓勵學生在學習過程中主動思考，例如：  * **嘗試理解每個數學公式背後的含義。** *\n",
            "\n",
            "**深入思考教材內容，而非只是 passively 接受。**  作者認為，**培養思考能力和習慣的最佳途徑就是在學習過程中不斷地思考和質疑。**\n",
            "\n",
            "Length of summary for segment 2: 246\n",
            "Time taken to generate summary for segment 2: 5.82 sec.\n",
            "\n",
            "----------------------------Summary of Segment 3----------------------------\n",
            "\n",
            "這段文字主要闡述了學習的廣泛性，強調學習不僅限於課業，更存在於生活的方方面面。作者認為，任何能讓人獲得增長、進步和快樂的事情都屬於學習。  作者以課餘活動為例，\n",
            "\n",
            "說明打球、爬山、旅行等活動都蘊含著學習的機會。打球不僅能鍛鍊身體，還能提升手腦協調能力、團隊精神和人際交往能力。爬山可以磨練意志、增長見識，旅行則能開拓視野、豐\n",
            "\n",
            "富人生經驗。  總之，學習不應被狹隘地定義為課堂知識的獲取，任何能帶來積極改變和快樂體驗的活動都值得我們投入時間和精力去學習。\n",
            "\n",
            "Length of summary for segment 3: 225\n",
            "Time taken to generate summary for segment 3: 6.77 sec.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 530.34ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 580.16ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "----------------------------Summary of Segment 5----------------------------\n",
            "\n",
            "這段文字主要探討課外活動的重要性，尤其對於電機工程學生。作者指出，雖然課外活動沒有考試和成績，看似「浪費時間」，但它們能培養重要的「軟實力」，例如團隊合作、領導\n",
            "\n",
            "能力、溝通技巧等。\n",
            "\n",
            "作者強調，現代電機工程項目需要團隊合作才能成功，而這些軟實力能幫助學生更好地融入團隊，從而推動項目發展。他也將軟實力定義為「硬實力」（專業知識）以外的能力。\n",
            "\n",
            "總而言之，作者鼓勵學生積極參與課外活動，培養軟實力，為將來在電機工程領域取得成功打下堅實基礎。\n",
            "\n",
            "Length of summary for segment 5: 220\n",
            "Time taken to generate summary for segment 5: 9.01 sec.\n",
            "\n",
            "----------------------------Summary of Segment 6----------------------------\n",
            "\n",
            "這段文字主要闡述了「軟實力」對於電機工程師的重要性。軟實力指的是人際交往能力，例如溝通、協調、說服、團隊合作和領導力等。作者認為，軟實力是許多成功電機工程師的關\n",
            "\n",
            "鍵因素。  雖然有些人天生具備較強的軟實力，但大多數人需要通過後天努力培養。作者以自身經歷為例，說明了大學期間積極參與課外活動和學習機會，幫助他提升了軟實力。\n",
            "\n",
            "作者強調了軟實力的重要性，並表示這一點在他過去的演講「信號與人生」中也有提及，希望藉此鼓勵更多電機工程師重視軟實力的培養。\n",
            "\n",
            "Length of summary for segment 6: 224\n",
            "Time taken to generate summary for segment 6: 6.72 sec.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 556.44ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 529.55ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 478.95ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 529.93ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 504.70ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 529.61ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 504.65ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 504.77ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 479.32ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 504.47ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 530.55ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 529.78ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n",
            "----------------------------Summary of Segment 7----------------------------\n",
            "\n",
            "這段文字主要探討電機系學生畢業後職涯發展的黃金時期與影響因素。作者認為35到55歲是黃金20年，在這之前雖然更好，但各方面尚未成熟；之後則會因年齡增長而打折扣。\n",
            "\n",
            "作者觀察到，有些畢業生的發展呈現穩定上升後趨於飽和；有些起步晚但後勁十足，最終達到較高成就；也有些初期表現亮眼，但後繼無力。當然，也有人一路向上攀升，沒有停滯。\n",
            "\n",
            "作者認為，影響職涯發展的關鍵並非單一科目的成績，而是實力、努力、大智和自我管理能力這四大因素。\n",
            "\n",
            "Length of summary for segment 7: 213\n",
            "Time taken to generate summary for segment 7: 33.93 sec.\n",
            "\n",
            "----------------------------Summary of Segment 8----------------------------\n",
            "\n",
            "這段文字主要討論了成功所需的四個要素：實力、努力、軟技能（self-skills）和大方向（大致）。\n",
            "\n",
            "**實力**來自於在電機工程專業領域的全面學習，避免過度專注於單一方向（overfitting）。\n",
            "\n",
            "**努力**的重要性不言而喻，長期堅持努力的人會與鬆懈的人拉開差距。\n",
            "\n",
            "**軟技能**指的是課業以外的能力，例如溝通、團隊合作等，這些能力在職場和生活中都非常重要。\n",
            "\n",
            "**大方向**指的是個人的長程目標，作者鼓勵大家思考自己想做什麼，並朝著目標努力。\n",
            "\n",
            "總而言之，作者認為成功需要結合專業能力、持續努力、良好的人際交往能力以及明確的人生目標。\n",
            "\n",
            "Length of summary for segment 8: 276\n",
            "Time taken to generate summary for segment 8: 6.55 sec.\n",
            "\n",
            "----------------------------Summary of Segment 9----------------------------\n",
            "\n",
            "這段文字的核心是關於**設定長程目標**的重要性。作者認為，找到值得投入 5 年、10 年甚至更長時間去努力的目标，並把它做到极致，是一件非常有意义的事情。\n",
            "\n",
            "作者強調，這個目標必須是自己真心覺得有意義、願意花費大量時間和精力去完成的。找到這樣的目標，就找到了人生的大致方向，也更容易取得成功。  总而言之，作者认为\n",
            "\n",
            "**明确的长期目标、强烈的意义感和持续的努力** 是成功的关键因素。\n",
            "\n",
            "Length of summary for segment 9: 195\n",
            "Time taken to generate summary for segment 9: 4.68 sec.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "    # 跳過第四段，因為 Gemini 會無原因的當掉\n",
        "    if index in [3]:\n",
        "        continue\n",
        "\n",
        "    # Record the start time.\n",
        "    start = time.time()\n",
        "\n",
        "    # Construct summarization prompt.\n",
        "    summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "    # We summarize each section that has been split up separately.\n",
        "    response = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "    # Calculate the execution time and round it to 2 decimal places.\n",
        "    cost_time = round(time.time() - start, 2)\n",
        "\n",
        "    # Print the summary and its length.\n",
        "    print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "    for text in textwrap.wrap(response, 80):\n",
        "        print(f\"{text}\\n\")\n",
        "    print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "    print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Record the result.\n",
        "    paragraph_summarizations.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amp-gOibmpvK",
        "outputId": "f0d1fe5e-fa3a-430c-c71c-c3bd71ad28bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of segment 1: 這段文字主要闡述了一個觀點：學問是做出來的，而非僅僅聽講或閱讀就能獲得。作者用兩個例子說明：\n",
            "\n",
            "1. **完成期末專案：** 將課堂所學知識整合應用，最終做出的成果能讓你真正掌握知識。\n",
            "2. **編寫複雜程式：** 通過實踐將演算法等抽象知識應用到具體程式中，才能真正理解和掌握。\n",
            "\n",
            "作者強調，動手實踐是將知識內化的關鍵，儘管這個過程可能沒有成績單上的數字來衡量，但它能讓學問真正成為自己的。 \n",
            "\n",
            "Summary of segment 2: 這段文字的核心觀點是：**真正的學習機會往往藏在看似辛苦、沒有直接回報的事情中，例如課程專案和深入思考。** 很多人因為怕累而逃避這些挑戰，但其實這些挑戰才能帶來最大的學習效益。\n",
            "\n",
            "作者以自身教學經驗為例，強調理解知識背後的意義比死記硬背公式更重要。他鼓勵學生在學習過程中主動思考，例如：\n",
            "\n",
            "* **嘗試理解每個數學公式背後的含義。**\n",
            "* **深入思考教材內容，而非只是 passively 接受。**\n",
            "\n",
            "作者認為，**培養思考能力和習慣的最佳途徑就是在學習過程中不斷地思考和質疑。** \n",
            "\n",
            "Summary of segment 3: 這段文字主要闡述了學習的廣泛性，強調學習不僅限於課業，更存在於生活的方方面面。作者認為，任何能讓人獲得增長、進步和快樂的事情都屬於學習。\n",
            "\n",
            "作者以課餘活動為例，說明打球、爬山、旅行等活動都蘊含著學習的機會。打球不僅能鍛鍊身體，還能提升手腦協調能力、團隊精神和人際交往能力。爬山可以磨練意志、增長見識，旅行則能開拓視野、豐富人生經驗。\n",
            "\n",
            "總之，學習不應被狹隘地定義為課堂知識的獲取，任何能帶來積極改變和快樂體驗的活動都值得我們投入時間和精力去學習。 \n",
            "\n",
            "Summary of segment 4: 這段文字主要探討課外活動的重要性，尤其對於電機工程學生。作者指出，雖然課外活動沒有考試和成績，看似「浪費時間」，但它們能培養重要的「軟實力」，例如團隊合作、領導能力、溝通技巧等。\n",
            "\n",
            "作者強調，現代電機工程項目需要團隊合作才能成功，而這些軟實力能幫助學生更好地融入團隊，從而推動項目發展。他也將軟實力定義為「硬實力」（專業知識）以外的能力。\n",
            "\n",
            "總而言之，作者鼓勵學生積極參與課外活動，培養軟實力，為將來在電機工程領域取得成功打下堅實基礎。 \n",
            "\n",
            "Summary of segment 5: 這段文字主要闡述了「軟實力」對於電機工程師的重要性。軟實力指的是人際交往能力，例如溝通、協調、說服、團隊合作和領導力等。作者認為，軟實力是許多成功電機工程師的關鍵因素。\n",
            "\n",
            "雖然有些人天生具備較強的軟實力，但大多數人需要通過後天努力培養。作者以自身經歷為例，說明了大學期間積極參與課外活動和學習機會，幫助他提升了軟實力。\n",
            "\n",
            "作者強調了軟實力的重要性，並表示這一點在他過去的演講「信號與人生」中也有提及，希望藉此鼓勵更多電機工程師重視軟實力的培養。 \n",
            "\n",
            "Summary of segment 6: 這段文字主要探討電機系學生畢業後職涯發展的黃金時期與影響因素。作者認為35到55歲是黃金20年，在這之前雖然更好，但各方面尚未成熟；之後則會因年齡增長而打折扣。\n",
            "\n",
            "作者觀察到，有些畢業生的發展呈現穩定上升後趨於飽和；有些起步晚但後勁十足，最終達到較高成就；也有些初期表現亮眼，但後繼無力。當然，也有人一路向上攀升，沒有停滯。\n",
            "\n",
            "作者認為，影響職涯發展的關鍵並非單一科目的成績，而是實力、努力、大智和自我管理能力這四大因素。 \n",
            "\n",
            "Summary of segment 7: 這段文字主要討論了成功所需的四個要素：實力、努力、軟技能（self-skills）和大方向（大致）。\n",
            "\n",
            "**實力**來自於在電機工程專業領域的全面學習，避免過度專注於單一方向（overfitting）。\n",
            "\n",
            "**努力**的重要性不言而喻，長期堅持努力的人會與鬆懈的人拉開差距。\n",
            "\n",
            "**軟技能**指的是課業以外的能力，例如溝通、團隊合作等，這些能力在職場和生活中都非常重要。\n",
            "\n",
            "**大方向**指的是個人的長程目標，作者鼓勵大家思考自己想做什麼，並朝著目標努力。\n",
            "\n",
            "總而言之，作者認為成功需要結合專業能力、持續努力、良好的人際交往能力以及明確的人生目標。 \n",
            "\n",
            "Summary of segment 8: 這段文字的核心是關於**設定長程目標**的重要性。作者認為，找到值得投入 5 年、10 年甚至更長時間去努力的目标，並把它做到极致，是一件非常有意义的事情。\n",
            "\n",
            "作者強調，這個目標必須是自己真心覺得有意義、願意花費大量時間和精力去完成的。找到這樣的目標，就找到了人生的大致方向，也更容易取得成功。\n",
            "\n",
            "总而言之，作者认为 **明确的长期目标、强烈的意义感和持续的努力** 是成功的关键因素。 \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# First, we collect all the summarizations obtained before and print them.\n",
        "\n",
        "collected_summarization = \"\"\n",
        "for index, paragraph_summarization in enumerate(paragraph_summarizations):\n",
        "    collected_summarization += f\"Summary of segment {index + 1}: {paragraph_summarization}\\n\"\n",
        "\n",
        "print(collected_summarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y08WjQxiuZ0k"
      },
      "source": [
        "#####Step2: After obtaining summaries for each smaller text piece separately, process these summaries to generate the final summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4GEhPEIudBe"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Gemini Multi-Stage Summarization: Total { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"在 500 字以內寫出以下文字的簡潔摘要，我會給你一億元：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdTjmyvfZwar"
      },
      "source": [
        "The code block below takes about **20** seconds to run when using the (1) **gemini-pro** model, (2) length of chunks is 512 and (3) maximum number of tokens is 550, but the actual time may vary depending on the condition of Colab and the status of the Google API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "6x5fn6I-msGC",
        "outputId": "63519dab-3c84-4ea3-c307-ddd7c76374f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1664.94ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n",
            "----------------------------Final Summary----------------------------\n",
            "\n",
            "##  文章摘要   這篇文章探討了學習的真諦、成功的要素以及電機工程師的職涯發展。  **學習的真諦：**  * 真正的學習來自於實踐，而非僅僅聽講或閱讀。\n",
            "* 積極參與專案、深入思考問題比死記硬背更重要。 * 學習無處不在，任何能帶來成長和快樂的活動都屬於學習。  **成功的要素：**  * **實力：**\n",
            "電機工程專業知識的全面學習。 * **努力：** 長期堅持不懈的努力。 * **軟技能：** 良好的人際交往能力，如溝通、團隊合作等。 * **大方向：**\n",
            "明確的長期目標和人生方向。  **電機工程師的職涯發展：**  * 35 到 55 歲是黃金時期，但成功並非一蹴而就，需要持續努力。 *\n",
            "影響職涯發展的關鍵因素是實力、努力、軟技能和明確的目標。  **文章主旨：**\n",
            "作者鼓勵讀者積極主動地學習，培養實力、努力、軟技能，並設定明確的長期目標，最終在電機工程領域乃至人生道路上取得成功。\n",
            "\n",
            "Length of final summary: 406\n",
            "Time taken to generate the final summary: 15.06 sec.\n"
          ]
        }
      ],
      "source": [
        "# Finally, we compile a final summary from the summaries of each section.\n",
        "\n",
        "# Record the start time.\n",
        "start = time.time()\n",
        "\n",
        "# Run final summarization.\n",
        "summarization_prompt = summarization_prompt_template.replace(\"<text>\", collected_summarization)\n",
        "final_summarization = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "# Calculate the execution time and round it to 2 decimal places.\n",
        "cost_time = round(time.time() - start, 2)\n",
        "\n",
        "# Print the summary and its length.\n",
        "print(f\"----------------------------Final Summary----------------------------\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 80):\n",
        "        print(f\"{text}\")\n",
        "print(f\"\\nLength of final summary: {len(final_summarization)}\")\n",
        "print(f\"Time taken to generate the final summary: {cost_time} sec.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPR2Am6omt0U",
        "outputId": "7f201ad7-1251-41eb-faa2-fff6b8e78525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final summary has been saved to ./final-summary-信號與人生-gemini-multi-stage.txt\n"
          ]
        }
      ],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-gemini-multi-stage.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    final_summarization = cc.convert(final_summarization)\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(final_summarization)\n",
        "\n",
        "print(f\"Final summary has been saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRWQTkFRlg83"
      },
      "source": [
        "## 來自 ChatGPT-4o 的答案\n",
        "### prompt:在 500 字以內寫出檔案中文字的摘要，其中包括要點和所有重要細節，我將給你一億元\n",
        "這段文字主要討論學問的獲得與人生中學習的重要性，分為課業內和課業外的學習兩部分。\n",
        "\n",
        "### 課業內學習：\n",
        "1. **實踐學習**：僅靠聽課和讀書可能無法真正掌握知識，必須通過實際操作來深化理解。例如，通過完成期末專案來整合學到的知識，寫程式來理解複雜的演算法等。\n",
        "2. **思考的培養**：上課時不僅要記住數學公式，還需理解其背後的意義，這有助於訓練思考能力。\n",
        "3. **全方面學習**：不要只注重成績單上的分數，多參與需要動手的課程和實驗，這樣才能全面提升學識。\n",
        "\n",
        "### 課業外學習：\n",
        "1. **廣泛學習**：學習不僅限於課堂，課業外的活動如打球、爬山、旅行等都能帶來增長和進步，是有價值的學習機會。\n",
        "2. **人際互動**：交朋友、參加活動、談戀愛等都是重要的學習機會，這些活動能夠增進人際交往能力和團隊合作精神，對個人成長非常重要。\n",
        "3. **軟實力**：除了專業技能，軟實力如溝通能力、領導力等也至關重要。這些能力大部分需要在課業外的實踐中培養，對未來的職業發展有重大影響。\n",
        "\n",
        "### 綜合學習的重要性：\n",
        "作者強調，電機工程師的成功除了專業實力（硬實力），還需要努力、目標感（大志）和軟實力。這四個因素共同決定了個人未來的職業發展。學習不應過於狹隘，而應注重全面發展，涵蓋課業內外的多方面學習，這樣才能真正實現長遠目標。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVl5n-11n_kT"
      },
      "source": [
        "\n",
        "## prompt:在 500 字以內寫出檔案的簡潔摘要，我將給你一億元\n",
        "這篇文章主要討論了學問的獲取和全面發展的重要性。作者強調，學問不是僅僅透過聽講和讀書就能獲得的，而是需要通過實踐和應用來真正掌握。這可以透過做實驗、完成期末專案、寫程式等方式實現。實踐能使理論知識內化成為自己的學問。\n",
        "\n",
        "此外，作者還探討了課業外活動的重要性，認為這些活動同樣能帶來成長和學習。例如，打球、爬山、旅行、交朋友、參加社團活動等，都能增長個人的軟實力（soft skills），如溝通能力、協調能力、團隊精神和領導能力。這些軟實力在電機工程師的職業生涯中至關重要，甚至可能比純粹的專業知識更具影響力。\n",
        "\n",
        "作者提到，個人的職業發展受四個主要因素影響：實力、努力、大志和軟實力。其中，實力來自於全面的學習和應用，努力則是持之以恆的付出，大志是長期目標和願景，而軟實力則需通過各種課業外的經歷來培養。\n",
        "\n",
        "總結來說，文章強調了理論與實踐結合的重要性，鼓勵學生積極參與課業外活動，以全面提升自己的能力，為將來的職業發展打下堅實基礎。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDZVeHCKvcMy"
      },
      "source": [
        "#### **If you want to use the method of Refinement, begin with this part.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1goEansHvc8C"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Gemini Refinement { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template** and **summarization_prompt_refine_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "\n",
        "# Initial prompt.\n",
        "# @markdown **summarization_prompt_template**: Initial prompt.\n",
        "summarization_prompt_template = \"請在 300 字以內，提供以下文字的簡潔摘要:<text>\" # @param {type:\"string\"}\n",
        "\n",
        "# Refinement prompt.\n",
        "# @markdown **summarization_prompt_refinement_template**: Refinement prompt.\n",
        "summarization_prompt_refinement_template = \"請在 500 字以內，結合原先的摘要和新的內容，提供簡潔的摘要:<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5AunhcUwDWh"
      },
      "source": [
        "Pipeline of the method of Refinement.\n",
        "\n",
        "Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "\n",
        "Step2: For each following document, the previous output is fed in along with the new document.\n",
        "\n",
        "Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "\n",
        "Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJMgqTC_2WD0"
      },
      "source": [
        "The code block below takes about **45** seconds to run when using the (1) **gemini-pro** model and (2) maximum number of tokens is 500, but the actual time may vary depending on the condition of Colab and the status of the Google API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DDWW_K4OwG1N",
        "outputId": "8de748b4-228d-4ee7-d9c8-929404e57bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------Summary of Segment 1----------------------------\n",
            "\n",
            "這段文字主要強調「學問是做出來的」。單純聽課或閱讀，知識容易遺忘，唯有透過實踐，例如完成期末專案或程式設計習題，將所學知識整合應用，才能真正內化為自身學問。這個\n",
            "\n",
            "過程如同將複雜演算法融會貫通，最終體現於作品中。因此，動手實踐至關重要，儘管成果不一定反映在成績單上，卻是將知識轉化為自身能力的關鍵。\n",
            "\n",
            "Length of summary for segment 1: 1\n",
            "Time taken to generate summary for segment 1: 5.87 sec.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 656.31ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 505.26ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 480.02ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n",
            "----------------------------Summary of the First 2 Segments----------------------------\n",
            "\n",
            "## 學問是做出來的，思考是關鍵  學習不只是聽課和閱讀，更需要動手實踐。就像完成期末專案或程式設計習題，將知識整合應用才能真正內化。這個過程如同將複雜演算法融\n",
            "\n",
            "會貫通，最終體現於作品中。雖然實作的成果不一定反映在成績單上，卻是將知識轉化為自身能力的關鍵。\n",
            "\n",
            "然而，許多人卻因為害怕辛苦而逃避實作，放棄了寶貴的學習機會。即使這些努力可能無法直接提升成績或幫助「overfitting」，卻能帶來更全面的學習和成長。\n",
            "\n",
            "除了實踐，培養思考習慣同樣重要。閱讀時，試著去理解每個公式和概念背後的意義，而非只是死記硬背。主動思考、深入理解，才能真正掌握知識，提升學習效率。\n",
            "\n",
            "Length of summary for the first 2 segments: 283\n",
            "Time taken to generate summary for the first 2 segments: 13.69 sec.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 506.07ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 831.20ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 504.90ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 529.81ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n",
            "----------------------------Summary of the First 3 Segments----------------------------\n",
            "\n",
            "## 學問是做出來的，思考是關鍵，而學習的樂趣無所不在  學習不只是聽課和閱讀，更需要動手實踐。將知識應用於專案或習題，如同將演算法融入作品，才能真正內化。雖然\n",
            "\n",
            "實作的成果不一定反映在成績單上，卻是將知識轉化為自身能力的關鍵。  然而，許多人害怕辛苦而逃避實作，放棄了寶貴的學習機會。即使這些努力可能無法直接提升成績，卻能\n",
            "\n",
            "帶來更全面的學習和成長。除了實踐，培養思考習慣同樣重要。閱讀時，試著去理解每個公式和概念背後的意義，而非只是死記硬背。主動思考、深入理解，才能真正掌握知識，提升\n",
            "\n",
            "學習效率。  學習的機會不僅限於課堂，更存在於生活的每個角落。任何能帶來成長、進步和快樂的事物都值得學習。打球能增進健康、團隊精神和人際互動；爬山挑戰自我、磨練\n",
            "\n",
            "意志；旅行開拓視野、增廣見聞。只要用心體會，你會發現學習的樂趣無所不在。\n",
            "\n",
            "Length of summary for the first 3 segments: 358\n",
            "Time taken to generate summary for the first 3 segments: 19.21 sec.\n",
            "\n",
            "----------------------------Summary of the First 4 Segments----------------------------\n",
            "\n",
            "## 學問是做出來的，思考是關鍵，而學習的樂趣無所不在  學習不只是聽課和閱讀，更需要動手實踐。將知識應用於專案或習題，如同將演算法融入作品，才能真正內化。實作\n",
            "\n",
            "的成果不一定反映在成績單上，卻是將知識轉化為自身能力的關鍵。許多人害怕辛苦而逃避實作，放棄了寶貴的學習機會。然而，這些努力能帶來更全面的學習和成長。\n",
            "\n",
            "除了實踐，培養思考習慣同樣重要。閱讀時，試著去理解每個公式和概念背後的意義，而非只是死記硬背。主動思考、深入理解，才能真正掌握知識，提升學習效率。  學習的機會\n",
            "\n",
            "不僅限於課堂，更存在於生活的每個角落。任何能帶來成長、進步和快樂的事物都值得學習。打球能增進健康、團隊精神和人際互動；爬山挑戰自我、磨練意志；旅行開拓視野、增廣\n",
            "\n",
            "見聞。  人際關係也是絕佳的學習場域。戀愛讓人體驗人際間的各種感覺和期待，交友則能學習人際互動和溝通技巧。參與社團活動，例如戲劇表演或幕後製作，都能在過程中獲得\n",
            "\n",
            "成長和進步。學習的樂趣無所不在，只要用心體會，就能在生活的每個面向中找到學習的機會。\n",
            "\n",
            "Length of summary for the first 4 segments: 440\n",
            "Time taken to generate summary for the first 4 segments: 10.07 sec.\n",
            "\n",
            "----------------------------Summary of the First 5 Segments----------------------------\n",
            "\n",
            "## 學問是做出來的，思考是關鍵，而學習的樂趣無所不在  學習不只是聽課和閱讀，更需要動手實踐，將知識應用於專案或習題，才能真正內化。實作的成果不一定反映在成績\n",
            "\n",
            "單上，卻是將知識轉化為自身能力的關鍵。除了實踐，培養思考習慣同樣重要，試著去理解每個公式和概念背後的意義，而非只是死記硬背。  學習的機會不僅限於課堂，更存在於\n",
            "\n",
            "生活的每個角落。打球、爬山、旅行、人際關係、社團活動等，都能帶來成長、進步和快樂。即使是看似與電機工程無關的活動，例如戲劇社，也能在過程中獲得成長和進步。  許\n",
            "\n",
            "多人害怕辛苦而逃避實作，放棄了寶貴的學習機會，只注重成績單上的分數，而忽略了軟實力的培養。然而，在職場上，軟實力與硬實力同樣重要。電機工程很少單打獨鬥，團隊合作\n",
            "\n",
            "至關重要。學習如何融入團隊、成為領導者、推動目標，這些軟實力都是從實踐中獲得的。\n",
            "\n",
            "因此，不要只追求成績單上的數字，更要積極參與各種活動，在實踐中學習，在生活中思考，才能獲得真正的成長和進步。\n",
            "\n",
            "Length of summary for the first 5 segments: 418\n",
            "Time taken to generate summary for the first 5 segments: 9.59 sec.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 529.58ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n",
            "----------------------------Summary of the First 6 Segments----------------------------\n",
            "\n",
            "## 學問是做出來的，思考是關鍵，而學習的樂趣無所不在  學習不只是聽課和閱讀，更需要動手實踐，將知識應用於專案或習題，才能真正內化。實作的成果不一定反映在成績\n",
            "\n",
            "單上，卻是將知識轉化為自身能力的關鍵。除了實踐，培養思考習慣同樣重要，試著去理解每個公式和概念背後的意義，而非只是死記硬背。  學習的機會不僅限於課堂，更存在於\n",
            "\n",
            "生活的每個角落。打球、爬山、旅行、人際關係、社團活動等，都能帶來成長、進步和快樂。即使是看似與電機工程無關的活動，例如戲劇社，也能在過程中獲得成長和進步。  許\n",
            "\n",
            "多人害怕辛苦而逃避實作，放棄了寶貴的學習機會，只注重成績單上的分數，而忽略了軟實力的培養。然而，在職場上，軟實力與硬實力同樣重要。電機工程很少單打獨鬥，團隊合作\n",
            "\n",
            "至關重要。學習如何融入團隊、成為領導者、推動目標，這些軟實力都是從實踐中獲得的。\n",
            "\n",
            "因此，不要只追求成績單上的數字，更要積極參與各種活動，在實踐中學習，在生活中思考，才能獲得真正的成長和進步。   軟實力，例如溝通能力、協調能力、團隊精神和領導\n",
            "\n",
            "能力等，對於電機工程師的成功至關重要。雖然有些人天生擅長人際交往，但大多數人的軟實力都需要後天培養。參與課外活動和各種學習機會，都有助於塑造個人的軟實力。作者以\n",
            "\n",
            "自身經歷為例，說明了在大學期間通過積極參與活動，成功提升了自己的軟實力，這也成為他日後成功的關鍵因素之一。\n",
            "\n",
            "Length of summary for the first 6 segments: 577\n",
            "Time taken to generate summary for the first 6 segments: 13.41 sec.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 504.29ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 580.03ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n",
            "----------------------------Summary of the First 7 Segments----------------------------\n",
            "\n",
            "學習不僅僅是為了成績單上的數字，更重要的是培養將知識應用於實踐的能力，並在生活中不斷思考和成長。除了專業知識，軟實力如溝通、團隊合作和領導力也至關重要，這些能力\n",
            "\n",
            "需要透過積極參與課外活動和各種學習機會來培養。  作者認為，35 到 55 歲是職業發展的黃金時期，而影響個人成就的關鍵因素並非單一學科成績，而是實力、努力、智\n",
            "\n",
            "慧和軟實力。有些人發展迅速但後勁不足，有些人起步較晚卻後發先至，而少數人則能持續不斷地向上攀升。這其中的差異就在於他們是否具備這四個關鍵因素。\n",
            "\n",
            "因此，我們應該跳脫追求單一學科成績的框架，積極參與實踐，培養軟實力，並將學習融入生活的每個角落，才能在職業生涯和人生道路上走得更穩、更遠。\n",
            "\n",
            "Length of summary for the first 7 segments: 305\n",
            "Time taken to generate summary for the first 7 segments: 13.64 sec.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 579.50ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The API call fails, wait for 1 second and try again.\n",
            "The API call fails, wait for 1 second and try again.\n",
            "----------------------------Summary of the First 8 Segments----------------------------\n",
            "\n",
            "學習的真諦不僅在於追求學業成績，更在於培養將知識應用於實踐的能力，並在人生旅程中不斷思考和成長。除了專業知識，軟實力如溝通、團隊合作和領導力也至關重要，這些能力\n",
            "\n",
            "需要透過積極參與課外活動和多元學習機會來培養。  作者認為，35 到 55 歲是職業發展的黃金時期，而影響個人成就的關鍵因素並非單一學科成績，而是實力、努力、智\n",
            "\n",
            "慧和軟實力。有些人發展迅速但後勁不足，有些人起步較晚卻後發先至，而少數人則能持續不斷地向上攀升。這其中的差異就在於他們是否具備這四個關鍵因素。  作者進一步解釋\n",
            "\n",
            "，實力並非局限於單一專業領域，而是透過全面學習，掌握各方面知識所形成的綜合能力。努力的重要性不言而喻，而軟實力則需要透過積極參與課外活動，在實踐中不斷累積。至於\n",
            "\n",
            "智慧，作者認為每個人可以設定自己的長程目標，並朝著目標不斷努力。\n",
            "\n",
            "總而言之，我們應該跳脫追求單一學科成績的框架，積極參與實踐，培養軟實力，並設定長遠目標，將學習融入生活的每個角落，才能在職業生涯和人生道路上走得更穩、更遠。\n",
            "\n",
            "Length of summary for the first 8 segments: 434\n",
            "Time taken to generate summary for the first 8 segments: 12.16 sec.\n",
            "\n",
            "----------------------------Summary of the First 9 Segments----------------------------\n",
            "\n",
            "## 學習的真諦：從課堂到人生，成就非凡的關鍵  學習的意義遠超於追求學業成績，更在於培養將知識應用於實踐的能力，並在人生旅程中不斷思考和成長。除了專業知識，軟\n",
            "\n",
            "實力如溝通、團隊合作和領導力也至關重要，這些能力需要透過積極參與課外活動和多元學習機會來培養。  作者認為，35 到 55 歲是職業發展的黃金時期，而影響個人成\n",
            "\n",
            "就的關鍵因素並非單一學科成績，而是實力、努力、智慧和軟實力。有些人發展迅速但後勁不足，有些人起步較晚卻後發先至，而少數人則能持續不斷地向上攀升。這其中的差異就在\n",
            "\n",
            "於他們是否具備這四個關鍵因素。  實力並非局限於單一專業領域，而是透過全面學習，掌握各方面知識所形成的綜合能力。努力的重要性不言而喻，而軟實力則需要透過積極參與\n",
            "\n",
            "課外活動，在實踐中不斷累積。至於智慧，作者認為每個人都應該設定自己的長程目標，並朝著目標不斷努力。  設定長程目標是至關重要的，它能指引我們努力的方向，賦予我們\n",
            "\n",
            "持續前進的動力。找到一件願意投入大量時間和精力，並認為極具意義的事情，將其設定為長程目標，就能在追求目標的過程中獲得成就感，並更容易取得成功。\n",
            "\n",
            "總而言之，我們應該跳脫追求單一學科成績的框架，積極參與實踐，培養軟實力，並設定長遠目標，將學習融入生活的每個角落，才能在職業生涯和人生道路上走得更穩、更遠。\n",
            "\n",
            "Length of summary for the first 9 segments: 553\n",
            "Time taken to generate summary for the first 9 segments: 10.77 sec.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    if index == 0:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Construct summarization prompt.\n",
        "        summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "        # Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "        first_paragraph_summarization = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(first_paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # Print the summary and its length.\n",
        "        print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "        for text in textwrap.wrap(first_paragraph_summarization, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for segment {index + 1}: {len(paragraph_summarizations)}\")\n",
        "        print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "    else:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Step2: For each following document, the previous output is fed in along with the new document.\n",
        "        chunk_text = f\"\"\"前 {index} 段的摘要: {paragraph_summarizations[-1]}\\n第 {index + 1} 段的內容: {chunk}\"\"\"\n",
        "\n",
        "        # Construct refinement prompt for summarization.\n",
        "        summarization_prompt = summarization_prompt_refinement_template.replace(\"<text>\", chunk_text)\n",
        "\n",
        "        # Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "        paragraph_summarization = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # print results.\n",
        "        print(f\"----------------------------Summary of the First {index + 1} Segments----------------------------\\n\")\n",
        "        for text in textwrap.wrap(paragraph_summarization, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for the first {index + 1} segments: {len(paragraph_summarization)}\")\n",
        "        print(f\"Time taken to generate summary for the first {index + 1} segments: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5jw0HwWwW83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d2815c-8a6d-4748-da24-0c72c32132cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final summary has been saved to ./final-summary-信號與人生-gemini-refinement.txt\n",
            "\n",
            "===== Below is the final summary (553 words) =====\n",
            "\n",
            "## 學習的真諦：從課堂到人生，成就非凡的關鍵  學習的意義遠超於追求學業成績，更在於培養將知識應用於實踐的能力，並在人生旅程中\n",
            "不斷思考和成長。除了專業知識，軟實力如溝通、團隊合作和領導力也至關重要，這些能力需要透過積極參與課外活動和多元學習機會來培養。\n",
            "作者認為，35 到 55 歲是職業發展的黃金時期，而影響個人成就的關鍵因素並非單一學科成績，而是實力、努力、智慧和軟實力。有些人\n",
            "發展迅速但後勁不足，有些人起步較晚卻後發先至，而少數人則能持續不斷地向上攀升。這其中的差異就在於他們是否具備這四個關鍵因素。  \n",
            "實力並非局限於單一專業領域，而是透過全面學習，掌握各方面知識所形成的綜合能力。努力的重要性不言而喻，而軟實力則需要透過積極參與課\n",
            "外活動，在實踐中不斷累積。至於智慧，作者認為每個人都應該設定自己的長程目標，並朝著目標不斷努力。  設定長程目標是至關重要的，它\n",
            "能指引我們努力的方向，賦予我們持續前進的動力。找到一件願意投入大量時間和精力，並認為極具意義的事情，將其設定為長程目標，就能在追\n",
            "求目標的過程中獲得成就感，並更容易取得成功。  總而言之，我們應該跳脫追求單一學科成績的框架，積極參與實踐，培養軟實力，並設定長\n",
            "遠目標，將學習融入生活的每個角落，才能在職業生涯和人生道路上走得更穩、更遠。\n"
          ]
        }
      ],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-gemini-refinement.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    paragraph_summarizations[-1] = cc.convert(paragraph_summarizations[-1])\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(paragraph_summarizations[-1])\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(paragraph_summarizations[-1])} words) =====\\n\")\n",
        "for text in textwrap.wrap(paragraph_summarizations[-1], 64):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3rwvZYdXieB"
      },
      "source": [
        "## **If you want to use Claude, begin with this part.**\n",
        "##### (1) You can refer to https://reurl.cc/yLy06D for obtaining Claude API key.\n",
        "##### (2) You can refer to https://docs.anthropic.com/claude/docs/models-overview for more details about which models you can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-51sj3lXieC"
      },
      "outputs": [],
      "source": [
        "def summarization(client, summarization_prompt, model_name=\"claude-3-sonnet-20240229\", temperature=0.0, top_p=1.0, max_tokens=512):\n",
        "    \"\"\"\n",
        "    (1) Objective:\n",
        "        - Use the Claude API to summarize a given text.\n",
        "\n",
        "    (2) Arguments:\n",
        "        - client: Claude API client.\n",
        "        - text: The text to be summarized.\n",
        "        - summarization_prompt: The summarization prompt.\n",
        "        - model_name: The model name, default is \"claude-3-sonnet-20240229\". You can refer to \"https://docs.anthropic.com/claude/docs/models-overview#model-comparison\" for more details.\n",
        "        - temperature: Controls randomness in the response. Lower values make responses more deterministic, default is 0.0.\n",
        "        - top_p: Controls diversity via nucleus sampling. Higher values lead to more diverse responses, default is 1.0.\n",
        "        - max_tokens: The maximum number of tokens to generate in the completion, default is 512.\n",
        "\n",
        "    (3) Return:\n",
        "        - The summarized text.\n",
        "\n",
        "    (4) Example:\n",
        "        - If the text is \"ABC\" and the summarization prompt is \"DEF\", system_prompt is \"GHI\", model_name is \"claude-3-sonnet-20240229\",\n",
        "          temperature is 0.0, top_p is 1.0, and max_tokens is 512, then you can call the function like this:\n",
        "\n",
        "              summarization(client=client, text=\"ABC\", summarization_prompt=\"DEF\", system_prompt=\"GHI\", model_name=\"claude-3-sonnet-20240229\", temperature=0.0, top_p=1.0, max_tokens=512)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = summarization_prompt\n",
        "\n",
        "    while True:\n",
        "\n",
        "        try:\n",
        "            # Use the Claude API to summarize the text.\n",
        "            message = client.messages.create(\n",
        "                model=model_name,\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=temperature,\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": user_prompt}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            break\n",
        "\n",
        "        except:\n",
        "            # If the API call fails, wait for 1 second and try again.\n",
        "            print(\"The API call fails, wait for 1 second and try again.\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    return message.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1mfcYh1Rwkrh"
      },
      "outputs": [],
      "source": [
        "# @title Parameter Setting of Claude { run: \"auto\" }\n",
        "''' ===== In this block, you can modify your desired parameters and set your Claude API key ===== '''\n",
        "\n",
        "# Your Claude API key.\n",
        "# @markdown **claude_api_key**: Your Claude api key.\n",
        "claude_api_key = \"YOUR_CLAUDE_API_KEY\" # @param {type:\"string\"}\n",
        "\n",
        "# The model name, default is \"claude-3-opus-20240229\". You can refer to \"https://docs.anthropic.com/claude/docs/models-overview#model-comparison\" for more details.\n",
        "# @markdown **model_name**: The model name, default is \"claude-3-opus-20240229\". You can refer to \"https://docs.anthropic.com/claude/docs/models-overview#model-comparison\" for more details.\n",
        "model_name = \"claude-3-opus-20240229\" # @param {type:\"string\"}\n",
        "\n",
        "# Controls randomness in the response. Lower values make responses more deterministic.\n",
        "# @markdown **temperature**: Controls randomness in the response. Lower values make responses more deterministic.\n",
        "temperature = 1 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "# Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "# @markdown **top_p**: Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n",
        "top_p = 1.0 # @param {type:\"slider\", min:0, max:1, step:0.1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-ivbHl6wrIj"
      },
      "outputs": [],
      "source": [
        "# Construct Claude client.\n",
        "client = anthropic.Anthropic(api_key=claude_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eDZJpX7xagQ"
      },
      "source": [
        "### We offer the following two methods for summarization.\n",
        "Reference: https://reurl.cc/VzagLA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEmYimdXxctB"
      },
      "source": [
        "#### **If you want to use the method of Multi-Stage Summarization, begin with this part.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4OBcswSxfUp"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Claude Multi-Stage Summarization: Paragraph { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# The maximum number of tokens to generate in the completion.\n",
        "# @markdown **max_tokens**: The maximum number of tokens to generate in the completion.\n",
        "max_tokens = 350 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown #### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"用 300 個字內寫出這段文字的摘要，其中包括要點和所有重要細節：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WClFqWBsyUWB"
      },
      "source": [
        "##### Step1: Split the long text into multiple smaller pieces and obtain summaries for each smaller text piece separately"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avQs_YFg2mK7"
      },
      "source": [
        "The code block below takes about **120** seconds to run when using the (1) **claude-3-opus-20240229** model, (2) length of chunks is 512 and (3) maximum number of tokens is 350, but the actual time may vary depending on the condition of Colab and the status of the Claude API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJlEpq4EqIAN"
      },
      "outputs": [],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    # Record the start time.\n",
        "    start = time.time()\n",
        "\n",
        "    # Construct summarization prompt.\n",
        "    summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "    # We summarize each section that has been split up separately.\n",
        "    response = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "    # Calculate the execution time and round it to 2 decimal places.\n",
        "    cost_time = round(time.time() - start, 2)\n",
        "\n",
        "    # Print the summary and its length.\n",
        "    print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "    for text in textwrap.wrap(response, 80):\n",
        "        print(f\"{text}\\n\")\n",
        "    print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "    print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Record the result.\n",
        "    paragraph_summarizations.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vzgd8rWqJP9"
      },
      "outputs": [],
      "source": [
        "# First, we collect all the summarizations obtained before and print them.\n",
        "\n",
        "collected_summarization = \"\"\n",
        "for index, paragraph_summarization in enumerate(paragraph_summarizations):\n",
        "    collected_summarization += f\"Summary of segment {index + 1}: {paragraph_summarization}\\n\\n\"\n",
        "\n",
        "print(collected_summarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qDxoyLpymA5"
      },
      "source": [
        "##### Step2: After obtaining summaries for each smaller text piece separately, process these summaries to generate the final summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E99bQfbgynXT"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Gemini Multi-Stage Summarization: Total { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "summarization_prompt_template = \"在 500 字以內寫出以下文字的簡潔摘要：<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-WvuFl4XV2J"
      },
      "source": [
        "The code block below takes about **25** seconds to run when using the (1) **claude-3-opus-20240229** model, (2) length of chunks is 512 and (3) maximum number of tokens is 550, but the actual time may vary depending on the condition of Colab and the status of the Claude API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qX4pa5QqKrc"
      },
      "outputs": [],
      "source": [
        "# Finally, we compile a final summary from the summaries of each section.\n",
        "\n",
        "# Record the start time.\n",
        "start = time.time()\n",
        "\n",
        "summarization_prompt = summarization_prompt_template.replace(\"<text>\", collected_summarization)\n",
        "\n",
        "# Run final summarization.\n",
        "final_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "# Calculate the execution time and round it to 2 decimal places.\n",
        "cost_time = round(time.time() - start, 2)\n",
        "\n",
        "# Print the summary and its length.\n",
        "print(f\"----------------------------Final Summary----------------------------\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 80):\n",
        "    print(f\"{text}\")\n",
        "print(f\"\\nLength of final summary: {len(final_summarization)}\")\n",
        "print(f\"Time taken to generate the final summary: {cost_time} sec.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldTq9WYlqL2U"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-claude-multi-stage.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    final_summarization = cc.convert(final_summarization)\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(final_summarization)\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(final_summarization)} words) =====\\n\")\n",
        "for text in textwrap.wrap(final_summarization, 64):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBI-Ba8QzLU8"
      },
      "source": [
        "#### **If you want to use the method of Refinement, begin with this part.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t2muOwUzNd0"
      },
      "outputs": [],
      "source": [
        "# @title Prompt Setting of Claude Refinement { run: \"auto\" }\n",
        "''' You can modify the summarization prompt and maximum number of tokens. '''\n",
        "''' However, DO NOT modify the part of <text>.'''\n",
        "\n",
        "# We set the maximum number of tokens.\n",
        "# @markdown **max_tokens**: We set the maximum number of tokens.\n",
        "max_tokens = 550 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ### Changing **summarization_prompt_template** and **summarization_prompt_refine_template**\n",
        "# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n",
        "\n",
        "# Initial prompt.\n",
        "# @markdown **summarization_prompt_template**: Initial prompt.\n",
        "summarization_prompt_template = \"請在 300 字以內，提供以下文字的簡潔摘要:<text>\" # @param {type:\"string\"}\n",
        "\n",
        "# Refinement prompt.\n",
        "# @markdown **summarization_prompt_refinement_template**: Refinement prompt.\n",
        "summarization_prompt_refinement_template = \"請在 500 字以內，結合原先的摘要和新的內容，提供簡潔的摘要:<text>\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JxW1AR2zZDL"
      },
      "source": [
        "Pipeline of the method of Refinement.\n",
        "\n",
        "Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "\n",
        "Step2: For each following document, the previous output is fed in along with the new document.\n",
        "\n",
        "Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "\n",
        "Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkm60apd2tQd"
      },
      "source": [
        "The code block below takes about **150** seconds to run when using the (1) **claude-3-opus-20240229** model and (2) maximum number of tokens is 500, but the actual time may vary depending on the condition of Colab and the status of the Claude API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Feco4LK4zazs"
      },
      "outputs": [],
      "source": [
        "paragraph_summarizations = []\n",
        "\n",
        "# First, we summarize each section that has been split up separately.\n",
        "for index, chunk in enumerate(chunks):\n",
        "\n",
        "    if index == 0:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Construct summarization prompt.\n",
        "        summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n",
        "\n",
        "        # Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n",
        "        first_paragraph_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(first_paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # Print the summary and its length.\n",
        "        print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n",
        "        for text in textwrap.wrap(response, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n",
        "        print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        # Record the start time.\n",
        "        start = time.time()\n",
        "\n",
        "        # Step2: For each following document, the previous output is fed in along with the new document.\n",
        "        chunk_text = f\"\"\"前 {index} 段的摘要: {paragraph_summarizations[-1]}\\n第 {index + 1} 段的內容: {chunk}\"\"\"\n",
        "\n",
        "        # Construct refinement prompt for summarization.\n",
        "        summarization_prompt = summarization_prompt_refinement_template.replace(\"<text>\", chunk_text)\n",
        "\n",
        "        # Step3: The LLM is instructed to refine the output based on the new document's information.\n",
        "        paragraph_summarization = summarization(client=client, summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n",
        "\n",
        "        # Record the result.\n",
        "        paragraph_summarizations.append(paragraph_summarization)\n",
        "\n",
        "        # Calculate the execution time and round it to 2 decimal places.\n",
        "        cost_time = round(time.time() - start, 2)\n",
        "\n",
        "        # print results.\n",
        "        print(f\"----------------------------Summary of the First {index + 1} Segments----------------------------\\n\")\n",
        "        for text in textwrap.wrap(paragraph_summarization, 80):\n",
        "            print(f\"{text}\\n\")\n",
        "        print(f\"Length of summary for the first {index + 1} segments: {len(paragraph_summarization)}\")\n",
        "        print(f\"Time taken to generate summary for the first {index + 1} segments: {cost_time} sec.\\n\")\n",
        "\n",
        "    # Step4: This process continues iteratively until all documents have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4BGRgvFz0eW"
      },
      "outputs": [],
      "source": [
        "''' In this block, you can modify your desired output path of final summary. '''\n",
        "\n",
        "output_path = f\"./final-summary-{suffix}-claude-refinement.txt\"\n",
        "\n",
        "# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n",
        "convert_to_tradition_chinese = False\n",
        "\n",
        "if convert_to_tradition_chinese == True:\n",
        "    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n",
        "    cc = OpenCC('s2t')\n",
        "    paragraph_summarizations[-1] = cc.convert(paragraph_summarizations[-1])\n",
        "\n",
        "# Output your final summary\n",
        "with open(output_path, \"w\") as fp:\n",
        "    fp.write(paragraph_summarizations[-1])\n",
        "\n",
        "# Show the result.\n",
        "print(f\"Final summary has been saved to {output_path}\")\n",
        "print(f\"\\n===== Below is the final summary ({len(paragraph_summarizations[-1])} words) =====\\n\")\n",
        "for text in textwrap.wrap(paragraph_summarizations[-1], 80):\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtQoyYjfdQLC"
      },
      "source": [
        "# Part5 - Check the correctness of the submission file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gclg3cORdiVR",
        "outputId": "394ea0fb-a536-4b5f-bb93-c01755551fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please save your submission file in JSON format.\n",
            "The format of your submission file is correct.\n",
            "Your final score is 0.\n"
          ]
        }
      ],
      "source": [
        "# Check the correctness of the submission file.\n",
        "import json\n",
        "import re\n",
        "\n",
        "your_submission_path = \"YOUR_SUBMISSION_PATH\"\n",
        "\n",
        "def check_format(your_submission_path):\n",
        "\n",
        "    final_score = 0\n",
        "\n",
        "    # check the extension of the file.\n",
        "    if not your_submission_path.endswith(\".json\"):\n",
        "        print(\"Please save your submission file in JSON format.\")\n",
        "\n",
        "    else:\n",
        "        try:\n",
        "            with open(your_submission_path, \"r\") as fp:\n",
        "                your_submission = json.load(fp)\n",
        "\n",
        "            evaluation_result = your_submission[\"history\"][0][\"messages\"][1][\"content\"]\n",
        "\n",
        "            if \"總分：\" not in evaluation_result:\n",
        "                # Correct format: 總分: <你的分數>\n",
        "                print(\"Please make sure that the correct format of final score is included in the evaluation result.\")\n",
        "                print(\"The correct format is 總分: <你的分數>. For example, 總分: 97\")\n",
        "                return False, final_score\n",
        "\n",
        "            evaluation_result = evaluation_result.strip()\n",
        "            score_pattern = r\"總分：\\d+\"\n",
        "            score = re.findall(score_pattern, evaluation_result)\n",
        "\n",
        "            if score:\n",
        "                final_score = score[-1].replace(\"總分：\", \"\")\n",
        "                if \"/100\" in final_score:\n",
        "                    final_score = final_score.replace(\"/100\", \"\")\n",
        "            else:\n",
        "                print(\"Please make sure that the final score is included in the evaluation result.\")\n",
        "                return False, final_score\n",
        "\n",
        "        except:\n",
        "            print(\"Open the file failed. Please check the file path or save your submission file in correct JSON format\")\n",
        "            return False, final_score\n",
        "\n",
        "    return True, final_score\n",
        "\n",
        "format_correctness, final_score = check_format(your_submission_path)\n",
        "if format_correctness== True:\n",
        "    print(\"The format of your submission file is correct.\")\n",
        "    print(f\"Your final score is {final_score}.\")\n",
        "else:\n",
        "    print(\"The format of your submission file is wrong.\")\n",
        "    print(\"Please check the format of your submission file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOOdcH9SmzFM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "voEioD2DCoeq",
        "z9QC8lG_QRZL",
        "hRzf_0cTV6TS",
        "GEmYimdXxctB",
        "eBI-Ba8QzLU8"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "111ebffdf10d46b181c5284ff81a70c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6b2021cf92d4b3eb7a755b5188ef081",
              "IPY_MODEL_eec7687c9f3f4fdf9cab005dffd01619",
              "IPY_MODEL_a24c013788c44e1693ea39d108e2923d"
            ],
            "layout": "IPY_MODEL_2d64cc890e5349c29a5f446475c11993"
          }
        },
        "a6b2021cf92d4b3eb7a755b5188ef081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b7a1b9f920a4f11bdb22c797d66bfd1",
            "placeholder": "​",
            "style": "IPY_MODEL_dd95c7ab4dbf479fa4ce629736aa2879",
            "value": "Downloading readme: 100%"
          }
        },
        "eec7687c9f3f4fdf9cab005dffd01619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3eb30a4c1144df991e507e2a55379da",
            "max": 305,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1358ce7679e4ed4b2396ccb48fc63c0",
            "value": 305
          }
        },
        "a24c013788c44e1693ea39d108e2923d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_549faff1f8064c1c86981a36b6279766",
            "placeholder": "​",
            "style": "IPY_MODEL_3029358340b248139f9fffa8431a0f4e",
            "value": " 305/305 [00:00&lt;00:00, 14.7kB/s]"
          }
        },
        "2d64cc890e5349c29a5f446475c11993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7a1b9f920a4f11bdb22c797d66bfd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd95c7ab4dbf479fa4ce629736aa2879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3eb30a4c1144df991e507e2a55379da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1358ce7679e4ed4b2396ccb48fc63c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "549faff1f8064c1c86981a36b6279766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3029358340b248139f9fffa8431a0f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed5d72fd50b44e2f9d7808bd751c7ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_728f1a80d6cc4197a126ea0b8a50da5f",
              "IPY_MODEL_bb0abf3d6285429a9243d5dfef8ce717",
              "IPY_MODEL_6f5cbc4990d545a5a21644a3b9883450"
            ],
            "layout": "IPY_MODEL_0694f31284274d85a4af9c69d6c86fb7"
          }
        },
        "728f1a80d6cc4197a126ea0b8a50da5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c416f7e576c14c469863408bf81aeea7",
            "placeholder": "​",
            "style": "IPY_MODEL_16909464160f4c4d9d658b06fcf60a79",
            "value": "Downloading data: 100%"
          }
        },
        "bb0abf3d6285429a9243d5dfef8ce717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a958b534b9d44df79678ba2241beaa63",
            "max": 3140168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2217b8c20efc48f8a85e1ec484c7f903",
            "value": 3140168
          }
        },
        "6f5cbc4990d545a5a21644a3b9883450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb006a5d26394e989381f69724095df3",
            "placeholder": "​",
            "style": "IPY_MODEL_071fe271e0574f8d848832985bbb6a0d",
            "value": " 3.14M/3.14M [00:00&lt;00:00, 13.0MB/s]"
          }
        },
        "0694f31284274d85a4af9c69d6c86fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c416f7e576c14c469863408bf81aeea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16909464160f4c4d9d658b06fcf60a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a958b534b9d44df79678ba2241beaa63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2217b8c20efc48f8a85e1ec484c7f903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb006a5d26394e989381f69724095df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "071fe271e0574f8d848832985bbb6a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0f43725845843b2982ddec349142aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0266e35b62e464795e33f6a58e7e80b",
              "IPY_MODEL_b38b2fac25474ff892bdaa080026233d",
              "IPY_MODEL_051802bc6fd14733bf04fd7e6aeaddc9"
            ],
            "layout": "IPY_MODEL_8868a0f308c247b8b57161a422c49b1b"
          }
        },
        "e0266e35b62e464795e33f6a58e7e80b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34799a762213410ba71dfcf23b76a4ae",
            "placeholder": "​",
            "style": "IPY_MODEL_bb90d47400404387bc0246e3581d76cf",
            "value": "Generating test split: 100%"
          }
        },
        "b38b2fac25474ff892bdaa080026233d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8cf8569afe44b63b603d19bcd399308",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34e3829530e849adaa76f4b23eb2370b",
            "value": 1
          }
        },
        "051802bc6fd14733bf04fd7e6aeaddc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af36759cdcb42508e49989b1d250e92",
            "placeholder": "​",
            "style": "IPY_MODEL_35445aaf815d45d1a405da1ba395200a",
            "value": " 1/1 [00:00&lt;00:00, 13.65 examples/s]"
          }
        },
        "8868a0f308c247b8b57161a422c49b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34799a762213410ba71dfcf23b76a4ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb90d47400404387bc0246e3581d76cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8cf8569afe44b63b603d19bcd399308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e3829530e849adaa76f4b23eb2370b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4af36759cdcb42508e49989b1d250e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35445aaf815d45d1a405da1ba395200a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}